{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Research Computing Documentation","text":"<p>Welcome!</p> <p>This site is a complete rewrite of our documentation and we are actively working on this process. Some page links or formatting may not work as intended. Please report any issues to help-rcc@mcw.edu.</p>"},{"location":"#introduction","title":"Introduction","text":"<p>Research Computing provides services and support for computational research at MCW. Our primary focus is High Performance Computing (HPC) and research data storage. We also work with MCW investigators to facilitate adoption and use of these advanced computational resources.</p>"},{"location":"#services","title":"Services","text":""},{"location":"#hpc-cluster","title":"HPC Cluster","text":"<p>The HPC cluster is the institution's primary computational resource, and has been available to MCW researchers since March 2021. The cluster consists of 3,360 CPU cores in 70 compute nodes. This includes large memory nodes and GPUs. All compute nodes are connected by a 100Gbps RoCEv2 network (ethernet equivalent to Infiniband). The cluster also includes a 215TB NVMe scratch storage filesystem. Please see the Quick Start guide for more detail.</p>"},{"location":"#reshpc","title":"ResHPC","text":"<p>Restricted HPC (ResHPC) is a secure way to access and utilize the HPC cluster. It is specifically designed for restricted datasets that have a defined Data Use Agreement (DUA), including dbGaP projects. The ResHPC service is built on the existing HPC cluster, but incorporates a separate, secure login method, and project specific accounts and directories. With ResHPC, you can work with familiar tools while also satisfying complex data provider security requirements. Please see the ResHPC overview to get started.</p>"},{"location":"#data-storage","title":"Data Storage","text":"<p>In addition to the cluster's scratch storage, RCC also provides general purpose research storage with a 1.8PB filesystem. This persistent storage is mounted on the cluster via NFS, or provided directly to user's via NFS and SMB. Please see the Storage Overview for more detail.</p>"},{"location":"#software","title":"Software","text":"<p>Cluster software installation and tuning services are available to all users. We will help install most supported software packages on the clusters, and when able, will advise on best use for our clusters. This might include advice on data staging, parallelization, memory utilization, etc. Please note that team members are not domain knowledge experts in the sciences, and will not advise you on the accuracy or applicability of any software package for your research. You can request software installation today.</p>"},{"location":"#consulting","title":"Consulting","text":"<p>We are glad to help with your research data and computing needs. Consulting topics might include how best to use the cluster for a workflow, software install, research data management, help with grants, security, etc. Project time, software development, paid support, and other dedicated resources are not available.</p>"},{"location":"#support-and-training","title":"Support and Training","text":""},{"location":"#email","title":"Email","text":"<p>Contact Research Computing support at help-rcc@mcw.edu.</p>"},{"location":"#workshops","title":"Workshops","text":"<p>RCC is planning workshops on a variety of topics. These are meant to include multiple levels of expertise and cover such topics as HPC, scripting, containers, etc. If you have a suggestion for a new workshop, please contact help-rcc@mcw.edu.</p> Title Level Slides HPC Cluster Onboarding Introductory Download"},{"location":"#virtual-office-hours","title":"Virtual Office Hours","text":"<p>Virtual office hours are held every Tuesday and Thursday 10AM-11AM.</p> <p>Join Us on Zoom (only available during meeting)</p> <p>After login, please use Chat to provide your username and a description of your question/issue.</p>"},{"location":"#acknowledgement","title":"Acknowledgement","text":"<p>Please include the following acknowledgement in any publication resulting from work on Research Computing resources:</p> <p>Acknowledgement</p> <p>This research was completed in part with computational resources and  technical support provided by the Research Computing Center at the  Medical College of Wisconsin.</p> <p>Check out the list of publications to see how Research Computing is enabling science at MCW.</p>"},{"location":"faq/","title":"Frequently Asked Questions","text":""},{"location":"faq/#access-login","title":"Access &amp; Login","text":"How do I get an account? <p>Submit an Account Request form.</p> How do I login? <p>The method you use to login depends on your computer and use case. We suggest you start with the quickstart guide.</p> Why can't I login? <ul> <li> <p>You might not have an account.</p> </li> <li> <p>You aren't using your MCW email username and password to login.</p> </li> <li> <p>You followed a guide and are using the word ''NetID'' as your username.</p> </li> </ul> Why don't I have access to my PI's <code>/group</code> directory? <p>You might not be correctly affiliated with your PI. Contact help-rcc@mcw.edu to correct this issue.</p> How do I get access to a collaborator's files? <p>Ask the collaborator PI to contact help-rcc@mcw.edu to request the access.</p> How do I add a student to my Research Group Storage security group? <ul> <li> <p>PIs should contact help-rcc@mcw.edu with the username of your new student.</p> </li> <li> <p>Non-PIs should contact help-rcc@mcw.edu with your username, the PI's username, and the username of the new student.</p> </li> </ul> How do I reset my password? <p>RCC uses the same credentials as MCW's other services. If you need to reset your password, use the Self Service Password Reset.</p>"},{"location":"faq/#job-management","title":"Job Management","text":"How do I submit a job to the HPC cluster? <p>You can submit a job to the HPC cluster with the <code>sbatch</code> command.</p> <pre><code>$ sbatch hpc-run.slurm\nSubmitted batch job 6782\n</code></pre> How do I run an interactive job on the cluster? <p>You can start an interactive job on the HPC cluster using the SLURM <code>srun</code> command.</p> <pre><code>$ srun --ntasks=1 --mem-per-cpu=4GB --time=01:00:00 --job-name=interactive --pty bash\n</code></pre> How do I check the status of my job? <p>You can find the current status of your job with the <code>squeue</code> command.</p> <pre><code>$ squeue -j 6696\nJOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n1234    normal Testing user  R      37:09      1 cn59\n</code></pre> How can I see the status of the HPC cluster? <p>You can find the current status of the HPC cluster resources with the <code>slurminfo</code> command.</p> <pre><code>$ slurminfo\n        QUEUE   FREE  TOTAL   FREE  TOTAL   RESORC    OTHER  MAXJOBTIME    CORES    NODE  GPU\n    PARTITION  CORES  CORES  NODES  NODES  PENDING  PENDING   DAY-HR:MN  PERNODE  MEM-GB (COUNT)\nnormal   1715   2880     34     60        0        0     7-00:00       48     360 -\n        bigmem      0     96      0      2        0        0     7-00:00       48    1500 -\n        gpu       279    288      3      6        0        0     7-00:00       48     360 gpu:v100(4)\n</code></pre> Why is my job not running? <p>There are several reasons that your job might not be running.</p> <ul> <li> <p>First, the cluster could be busy and your job might be waiting for resources to become available. The cluster is a shared resource and some wait time, while often short or non-existent, can be expected.</p> </li> <li> <p>Your job might be requesting resources that don't exist. Check the output of <code>squeue -j JobID</code>, where JobID is your SLURM job number. In the final column '''Nodelist (Reason)''' you might see '''PD''' followed by a reason. This could indicate that your job is temporarily waiting for resources (see above) or is blocked.</p> </li> </ul> Can I run a task/script on a login node? <p>Yes, but you should make sure you know exactly how many cores and memory the task will use. Additionally, you should make sure this task will not run for more than 30 min. Examples of allowed tasks might be a pre- or post- processing task for your input/output files. This might also include compiling or installing software. In general, please try to run all computationally intensive tasks on on the cluster compute nodes. For details see the User Etiquette Guide.</p> Can I have root or sudo access on a compute node? <p>No. RCC does not allow root and/or sudo access on any system.</p> What if my job requires more than 7 days? Can I extend my job time? <p>Yes. After you start the job, email the job number and time extension request to help-rcc@mcw.edu.</p>"},{"location":"faq/#software","title":"Software","text":"What software is available on the HPC cluster? <p>You can list all available software on the cluster with the <code>module avail</code> command. See the cluster software guide for details.</p> Can I install my own software? <p>Yes, you may install your own software. The process will vary depending on the type of software. Please contact help-rcc@mcw.edu if you need assistance.</p> Will RCC install my software for me? <p>You may request to have RCC install your software on the cluster. RCC will make a best effort but cannot guarantee that your software will run on the cluster. Please send software installation requests to help-rcc@mcw.edu.</p> How do I install an R package? <p>You can install your own R packages. See the R guide for details. Please also that RCC has centrally installed many packages that are either commonly used, or difficult to install. We suggest to check first if your package is already installed. Please contact help-rcc@mcw.edu for assistance or to have RCC install the package for you.</p> How do I install a Python package? <p>You can install your own Python packages using the system Python, a local Python, a virtual environment, or a conda environment. See the Python guide for details. Please also that RCC has centrally installed many packages that are either commonly used, or difficult to install. We suggest to check first if your package is already installed. Please contact help-rcc@mcw.edu for assistance or to have RCC install the package for you.</p> Can I use Docker on the cluster? <p>No. Docker is not installed or allowed on RCC systems due to security. However, RCC does provide a container solution called Singularity, which can import Docker containers to run on the cluster.</p>"},{"location":"faq/#data-transfer-storage","title":"Data Transfer &amp; Storage","text":"How do I check my available storage directories and utilization? <p>You can easily find your available storage directories and current utilization with the <code>mydisks</code> command.</p> <pre><code>$ mydisks\n======My Lab======\nSize  Used Avail Use% File\n47G   29G   19G  61% /home/user\n932G  158G  774G  17% /group/pi\n4.6T     0  4.6T   0% /scratch/g/pi\n</code></pre> Why does my quota show as less space? <p>Your computer reports storage utilization in base-2 math and the storage system quotas use base-10 math. So, if your quota is 1TB, the <code>mydisks</code> command will show 932GB. Please note that this is a difference in mathematical representation of the same value. While the <code>mydisks</code> command shows less space, you are still able to use your full quota.</p> What types of storage are available? <p>RCC offers multiple types of storage to all users. Each storage type has a unique path on the cluster, and a unique use-case. Some storage is meant only for use with the cluster, while other storage like Research Group Storage can be used as generalized Windows storage. Please see the Storage Overview for details.</p> Can I increase my storage limits? <p>Your home directory limit cannot be increased. You scratch directory limit may be increase upon request but this is subject to availability. Your <code>/group</code> Research Group Storage directory may be increased by purchasing additional space.</p> Why is <code>/group</code> not available on HPC cluster compute nodes? <p>The file system that contains <code>/group</code> is not designed for performance computing. In order to preserve every user's experience with <code>/group</code>, it is not available on compute nodes. You should follow the scratch directory procedures to make sure your data is available to your cluster job.</p> Can I mount my own storage to the cluster? <p>No. RCC provides storage that is mounted to the cluster. This storage is specifically designed to work within the cluster network and meets performance requirements.</p> Where can I store reference data? <p>Reference data will be stored at <code>/hpc/refdata</code> upon request. Please see Reference Data for more information.</p> How do I use my group storage for collaboration outside my lab? <p>Your lab group storage can be used to collaborate with non-lab members. This is done with by-request project directories. For example, if lab <code>pi</code> would like to collaborate with some data for a project called <code>zephyr</code>, then the lab PI would contact RCC to create a project directory.</p> <pre><code>$ ls -l /group/pi\ntotal 8\ndrwxrws---. 3 root sg-pi-zephyr 512 Mar 26 13:52 zephyr\ndrwxrws---. 4 root sg-pi       1024 May 19 14:04 work\n</code></pre> <p>In addition to the usual <code>work</code> directory, there is now a <code>zephyr</code> project directory, which is controlled by the <code>sg-pi-zephyr</code> security group. Project data would go in that directory, and any number of collaborators (MCW researchers) can be added to the security group.</p> Why did my Windows SMB storage share stopped working? <p>Stale connections for Windows shares are not uncommon. If your storage share stopped working, chances are this is a stale connection. This is especially true if the storage was working one day, and you cannot connect the next day. To fix this issue, you'll need to remount the storage with the following steps.</p> <ul> <li> <p>Open Windows File Explorer and right-click on the drive, then select Disconnect.</p> </li> <li> <p>Remount the storage using this guide https://support.microsoft.com/en-us/windows/map-a-network-drive-in-windows-10-29ce55d1-34e3-a7e2-4801-131475f9557d. In step #4, make sure to select <code>Connect using different credentials</code> during that process. If you are on a non-MCW managed computer, please enter your MCW username with the \"MCWCORP\\\" domain prefix (example MCWCORP\\jsmith).</p> </li> </ul>"},{"location":"faq/#open-ondemand","title":"Open OnDemand","text":"Why does the Open OnDemand web page not load? <p>Open OnDemand supports most modern browsers. However, there is no IE 11 support. To have the best experience using Open OnDemand, use the latest versions of Google Chrome, Mozilla Firefox or Microsoft Edge.</p> How do I use RStudio on the cluster? <p>Open OnDemand has a built-in RStudio app. You can use this to get a RStudio session on a compute node that you can access via your web browser. See the RStudio on Open OnDemand guide for details.</p> How do I get a Jupyter Notebook on the cluster? <p>Open OnDemand has a built-in Jupyter Notebook app. You can use this to get a Jupyter Notebook on a compute node that you can access via your web browser. See the Jupyter on Open OnDemand guide for details.</p> Can I get a virtual desktop on the cluster? <p>Yes, Open OnDemand does have a virtual desktop app built-in. However, since the cluster compute nodes are not designed or built for desktop use, functionality may be limited.</p>"},{"location":"faq/#about-rcc","title":"About RCC","text":"What is RCC? <p>The Research Computing Center (RCC) provides infrastructure and campus-wide access to resources required for computationally intensive biomedical research. This includes shared hardware and research-specific software which is supported by MCW and research grants.</p> How do I acknowledge Research Computing resources in my publication? <p>Please include the following acknowledgement in any publication resulting from work on Research Computing resources:</p> <p>Acknowledgement</p> <p>This research was completed in part with computational resources and technical support provided by the Research Computing Center at the Medical College of Wisconsin.</p> Where can I find other publications from RCC users? <p>Check out the list of publications to see how Research Computing is enabling science at MCW. The list of publications is updated periodically. Please contact help-rcc@mcw.edu to add your publication.</p> Where can I find RCC information for my grant submission? <p>RCC provides boilerplate language for all current systems including cluster, storage, network, staffing, etc. See Grant Assistance for details. Please note that RCC will also provide a letter of support upon request.</p>"},{"location":"grants/","title":"Grant Assistance","text":"<p>Contact RCC</p> <p>Please contact help-rcc@mcw.edu to determine if you have the computing resources necessary for your proposal.</p> <p>Below are descriptions of RCC services that can be used when preparing the resources section of grant proposals. Please feel free to copy relevant portions of this text.</p>"},{"location":"grants/#overview","title":"Overview","text":"<p>The MCW Research Computing Center (RCC) is a division within MCW Information Services. RCC provides campus-wide access to high performance computing (HPC) resources required for computationally-intensive biomedical research. RCC is institutionally supported and available to all MCW students, staff, and faculty. RCC services and operations are governed by representatives of the MCW Faculty in partnership with RCC leadership.</p>"},{"location":"grants/#high-performance-computing","title":"High Performance Computing","text":"<p>The High Performance Computing (HPC) environment includes 68 computational nodes, 3264 processor cores, 28.3 TB of memory, and 24 graphical processing units (GPUs). The nodes are interconnected by 100 Gb/s Ethernet, allowing efficient parallel computing for both CPU and GPU intensive workloads. Job submission and scheduling is controlled by the Simple Linux Utility for Resource Management (SLURM). SLURM is an open-source HPC scheduling system that automates job submission, controls resource access, and maintains fair use of all systems. Each compute node includes a standardized operating system image, set of compilers, math libraries, and system software. RCC also supports a variety of open-source software and containerized workloads are supported.</p>"},{"location":"grants/#restricted-hpc","title":"Restricted HPC","text":"<p>Restricted HPC (ResHPC) is a secure way to access and utilize the HPC cluster. It is specifically designed with security enhancements for restricted datasets that have a defined Data Use Agreement (DUA), including dbGaP projects. The ResHPC service is built on the existing HPC cluster, but incorporates a separate, secure login method, and project specific accounts and directories.</p>"},{"location":"grants/#data-storage","title":"Data Storage","text":"<p>The system includes a 215 TB NVMe scratch file system enabling high-performance file I/O during job processing. A second 1.77 PB file system provides persistent storage for active projects. A 100 Gbps network provides fast data transfer between file systems.</p> <p>RCC provides 1 TB of persistent storage to any MCW faculty member for free. Additional persistent storage is available for $60 per TB per year.</p>"},{"location":"grants/#datacenter-and-network-facilities","title":"Datacenter and Network Facilities","text":"<p>All RCC hardware is housed in a managed datacenter. This facility includes redundant HVAC cooling systems, redundant power distribution, UPS battery backup, and diesel-powered backup generators. All equipment is on dedicated subnets providing high-capacity redundant (1Gb) networking. The datacenter also has Internet 2 access through WiscNet.</p>"},{"location":"grants/#staff-and-support","title":"Staff and Support","text":"<p>RCC is supported by a team of research computing specialists with additional support and assistance from several central IT teams. RCC provides training, software installation and setup, end-user support, and troubleshooting. This includes consultation with full-time RCC staff members who have extensive system administration and research computing experience.</p>"},{"location":"news/","title":"Recent News","text":"<p> <p></p>"},{"location":"pubs/","title":"Publications supported by Research Computing","text":"<p>Acknowledging Research Computing is easy to do and helps people understand how important RCC resources are to you and MCW.</p> <p>All you have to do is include the following statement in your publication:</p> <p>Acknowledgement</p> <p>This research was completed in part with computational resources and technical support provided by the Research Computing Center at the Medical College of Wisconsin.</p>"},{"location":"pubs/#2023","title":"2023","text":"<p>Comparison of Various Metrics of Repetitive Head Impact Exposure And Their Associations With Neurocognition in Collegiate-Aged Athletes Amadon GK, Goeckner BD, Brett BL, Meier TB</p>"},{"location":"pubs/#2022","title":"2022","text":"<p>Natural variation in the binding pocket of a parasitic flatworm TRPM channel resolves the basis for praziquantel sensitivity Rohr CM, Sprague DJ, Park S, Marchant JS</p> <p>Structural studies of human fission protein FIS1 reveal a dynamic region important for GTPase DRP1 recruitment and mitochondrial fission Egner JM, Nolden KA, Cleland Harwig M, Bonate RP, De Anda J, Tessmer MH, Noey EL, Ihenacho UK, Liu Z, Peterson FC, Wong GCL, Widlansky ME, Hill RB</p> <p>Spatial transcriptomics demonstrates the role of CD4 T cells in effector CD8 T cell differentiation during chronic viral infection Topchyan P, Zander R, Kasmani MY, Nguyen C, Brown A, Lin S, Burns R, Cui W</p> <p>Clonal lineage tracing reveals mechanisms skewing CD8+ T cell fate decisions in chronic infection Kasmani MY,Zander R, Chung HK, Chen Y, Khatun A, Damo M, Topchyan P, Johnson KE, Levashova D, Burns R, Lorenz UM, Tarakanova VL, Joshi NS, Kaech SM, Cui W</p> <p>Tension-bending risk curves for the ATD lower lumbar spine subjected to oblique impact under FAA emergency landing conditions Somasundaram K, Humm JR, Yoganandan N, Moorcroft DM, Pintar FA</p> <p>Occupant Injury and Response on Oblique-Facing Aircraft Seats: A Computational Study Somasundaram K, Humm JR, Khandelwal P, Umale S, Moorcroft DM, Pintar FA</p> <p>Multi-Omic Integration by Machine Learning (MIMaL) Dickinson Q, Aufschnaiter A, Ott M, Meyer JG</p> <p>Group 3 innate lymphoid cells require BATF to regulate gut homeostasis in mice Wu X, Khatun A, Kasmani MY, Chen Y, Zheng S, Atkinson S, Nguyen C, Burns R, Taparowsky EJ, Salzman NH, Hand TW, Cui W</p> <p>A single, peri-operative antibiotic can persistently alter the post-operative gut microbiome after Roux-en-Y gastric bypass Fernando DG, Saravia FL, Atkinson SN, Barron M, Kirby JR, Kindel TL</p> <p>Bias or biology? Importance of model interpretation in machine learning studies from electronic health records Momenzadeh A, Shamsa A, Meyer JG</p> <p>Conformational selection guides b-arrestin recruitment at a biased G protein\u2013coupled receptor Kleist AB, Jenjak S, Sente A, Laskowski LJ, Szpakowska M, Calkins MM, Anderson EI, McNally LM, Heukers R, Bobkov V, Peterson FC, Thomas MA, Chevigne A, Smit MJ, McCorvy JD, Babu MM, Volkman BF</p> <p>Autoreactive CD8 T cells in NOD mice exhibit phenotypic heterogeneity but restricted TCR gene usage Kasmani MY, Ciecko AE, Brown AK, Petrova G, Gorski J, Chen Y, Cui W</p> <p>Single-cell immune profiling reveals a developmentally distinct CD4+ GM-CSF+ T-cell lineage that induces GI tract GVHD Piper C, Hainstock E, Yin-Yuan C, Chen Y, Khatun A, Kasmani MY, Evans J, Miller JA, Gorski J, Cui W, Drobyski, WR</p> <p>Tfh-cell-derived interleukin 21 sustains effector CD8+ T cell responses during chronic viral infection Zander R, Kasmani MY, Chen Y, Topchyan P, Shen J, Zheng S, Burns R, Ingram J, Cui C, Joshi N, Craft J, Zajac A, Cui W</p> <p>Cytokine and Nitric Oxide-Dependent Gene Regulation in Islet Endocrine and Nonendocrine Cells Stancill JS, Kasmani MY, Khatun A, Cui W, Corbett JA</p> <p>The non-ELR CXC chemokine encoded by human cytomegalovirus UL146 genotype 5 contains a C-terminal \u03b2-hairpin and induces neutrophil migration as a selective CXCR2 agonist Berg C, Wedemeyer MJ, Melynis M, Schlimgen RR, Hansen LH, V\u00e5ben\u00f8 J, Peterson FC, Volkman BF, Rosenkilde MM, L\u00fcttichau HR</p> <p>Investigating the overlapping associations of prior concussion, default mode connectivity, and executive function-based symptoms Brett BL, Bryant AM, Espa\u00f1a LY, Mayer AR, Meier TB</p> <p>BATF promotes group 2 innate lymphoid cell\u2013mediated lung tissue protection during acute respiratory virus infection Wu X, Kasmani MY, Zheng S, Khatun A, Chen Y, Winkler W, Zander R, Burns R, Taparowsky EJ, Sun J, Cui W</p> <p>Enhanced interpretation of 935 hotspot and non-hotspot RAS variants using evidence-based structural bioinformatics Tripathi S, Dsouza NR, Mathison AJ, Leverence E, Urrutia R, Zimmermann MT</p> <p>Improved prediction of older adult discharge after trauma using a novel machine learning paradigm Morris RS, Tignanelli CJ, deRoon-Cassini T, Laud P, Sparapani R</p> <p>The association between concussion history and increased symptom severity reporting is independent of common medical comorbidities, personality factors, and sleep quality in collegiate athletes Brett BL, Nelson LD, Meier TB</p> <p>Positional SHAP (PoSHAP) for Interpretation of machine learning models trained from biological sequences Dickinson Q, Meyer JG</p>"},{"location":"pubs/#2021","title":"2021","text":"<p>Interpreting Sequence Variation in PDAC-Predisposing Genes Using a Multi-Tier Annotation Approach Performed at the Gene, Patient, and Cohort Level Zimmermann MT, Mathison AJ, Stodola T, Evans DB, Abrudan JL, Demos W, Tschannen M, Aldakkak M, Geurts J, Lomberk G, Tsai S, Urrutia RA</p> <p>Structural bioinformatics enhances mechanistic interpretation of genomic variation, demonstrated through the analyses of 935 distinct RAS family mutations Tripathi S, Dsouza NR, Urrutia R, Zimmermann MT</p> <p>Association of Previous Concussion with Hippocampal Volume and Symptoms in Collegiate-Aged Athletes Meier TB, Espa\u00f1a LY, Kirk AJ, Nader AM, Powell JE, Nelson LD, Mayer AR, Brett BL</p> <p>Association of Head Impact Exposure with White Matter Macrostructure and Microstructure Metrics Brett BL, Koch KM, Muftuler LT, Budde M, McCrea MA, Meier TB</p> <p>Acute post-concussive assessments of brain tissue magnetism using magnetic resonance imaging Koch KM, Nencka AS, Swearingen B, Bauer A, Meier TB, McCrea MA</p> <p>P2T2: Protein Panoramic annoTation Tool for the interpretation of protein coding genetic variants DeVoe E, Oliver GR, Zenka R, Blackburn PR, Cousin MA, Boczek NJ, Kocher JA, Urrutia R, Klee EW, Zimmermann MT</p> <p>Influence of cervical spine sagittal alignment on range of motion after corpectomy: a finite element study John JD, Kumar GS, Yoganandan N, Rajshekhar V</p> <p>BATF regulates progenitor to cytolytic effector CD8+ T cell transition during chronic viral infection Chen Y, Zander RA, Wu X, Schauder DM, Kasmani MY, Shen J, Zheng S, Burns R, Taparowsky EJ, Cui W</p> <p>E2A-regulated epigenetic landscape promotes memory CD8 T cell differentiation Schauder DM, Shen J, Chen Y, Kasmani MY, Kudek MR, Burns R, Cui W</p> <p>Single-cell RNA sequencing of mouse islets exposed to proinflammatory cytokines Stancill JS, Kasmani MY, Khatun A, Cui W, Corbett JA</p> <p>Suppressive neutrophils require PIM1 for metabolic fitness and survival during chronic viral infection Volberding PJ, Xin G, Kasmani MY, Khatun A, Brown AK, Nguyen C, Stancill JS, Martinez E, Corbett JA, Cui W</p>"},{"location":"pubs/#2020","title":"2020","text":"<p>Conditional Deletion of PGC-1\u03b1 Results in Energetic and Functional Defects in NK Cells Gerbec ZJ, Hashemi E, Nanbakhsh A, Holzhauer S, Yang C, Mei A, Tsaih SW, Lemke A, Flister MJ, Riese MJ, Thakar MS, Malarkannan S</p> <p>The chemokine X-factor: Structure-function analysis of the CXC motif at CXCR4 and ACKR3 Wedemeyer MJ, Mahn SA, Getschman AE, Crawford KS, Peterson FC, Marchese A, McCorvy JD, Volkman BF</p> <p>Single-cell lineage mapping of a diverse virus-specific naive CD4 T cell repertoire Khatun A, Kasmani MY, Zander R, Schauder DM, Snook JP, Shen J, Wu X, Burns R, Chen YG, Lin CW, Williams MA</p> <p>Comparative modeling and docking of chemokine-receptor interactions with Rosetta Wedemeyer MJ, Mueller BK, Bender BJ, Meiler J, Volkman BF</p> <p>Amygdala response to emotional faces in adolescents with persistent post-concussion symptoms Bohorquez-Montoya L, Espa\u00f1a LY, Nader AM, Furger RE, Mayer AR, Meier TB</p> <p>Accurate segmentation of prostate cancer histomorphometric features using a weakly supervised convolutional neural network Bukowy JD, Foss H, McGarry SD, Lowman AK, Hurrell SL, Iczkowski KA, Banerjee A, Bobholz SA, Barrington A, Dayton A, Unteriner JG, Jacobsohn KM, See WA, Nevalainen MT, Nencka AS, Ethridge T, Jarrard DF, LaViolette PS</p> <p>Systemic inflammation moderates the association of prior concussion with hippocampal volume and episodic memory in high school and collegiate athletes Brett BL, Savitz J, Nitta M, Espana L, Teague TK, Nelson LD, McCrea MA, Meier TB</p> <p>Genetic variants in DGAT1 cause diverse clinical presentations of malnutrition through a specific molecular mechanism Gupta A, Dsouza NR, Zarate YA, Lombardo R, Hopkin R, Linehan AR, Simpson J, McCarrier J, Agre KE, Gavrilova RH, Stephens MC, Grothe RM, Monaghan KG, Xie Y, Basel D, Urrutia RA, Cole CR, Klee EW, Zimmermann MT</p> <p>Cumulative effects of prior concussion and primary sport participation on brain morphometry in collegiate athletes: a study from the NCAA\u2013DoD CARE consortium Brett BL, Bobholz SA, Espa\u00f1a LY, Huber DL, Mayer AR, Harezlak J, Broglio SP, McAllister TW, McCrea MA, Meier TB, CARE Consortium Investigators</p> <p>Resting-state fMRI metrics in acute sport-related concussion and their association with clinical recovery: a study from the NCAA-DOD CARE Consortium Meier TB, Giraldo-Chica M, Espa\u00f1a LY, Mayer AR, Harezlak J, Nencka AS, Wang Y, Koch KM, Wu YC, Saykin AJ, Giza CC, Goldman J, DiFiori JP, Guskiewicz KM, Mihalik JP, Brooks A, Broglio SP, McAllister T, McCrea MA</p> <p>Novel destabilizing Dynactin variant (DCTN1 p. Tyr78His) in patient with Perry syndrome \u010cierny M, Hooshmand SI, Fee D, Tripathi S, Dsouza NR, Kirschner AL, Zimmermann MT, Brennan R</p> <p>Optimization of hyperparameters for SMS reconstruction Muftuler LT, Arpinar VE, Koch K, Bhave S, Yang B, Kaushik S, Banerjee S, Nencka A</p> <p>Amygdala functional connectivity features in grief: a pilot longitudinal study Chen G, Ward BD, Claesges SA, Li SJ, Goveas JS</p> <p>Serial diffusion kurtosis magnetic resonance imaging study during acute, subacute, and recovery periods after sport-related concussion Muftuler LT, Meier TB, Keith M, Budde MD, Huber DL, McCrea MA</p> <p>Covalent-fragment screening of BRD4 identifies a ligandable site orthogonal to the acetyl-lysine binding sites Olp MD, Sprague DJ, Goetz CJ, Kathman SG, Wynia-Smith SL, Shishodia S, Summers SB, Xu Z, Statsyuk AV, Smith BC</p>"},{"location":"pubs/#2019","title":"2019","text":"<p>Integration of Multi-level Molecular Scoring for the Interpretation of RAS-Family Genetic Variation Tripathi S, Dsouza NR, Urrutia RA, Zimmermann MT</p> <p>Modeling the complete chemokine\u2013receptor interaction Wedemeyer MJ, Mueller BK, Bender BJ, Meiler J, Volkman BF</p> <p>Prevalence of potentially clinically significant MRI findings in athletes with and without sport-related concussion Klein AP, Tetzlaff JE, Bonis JM, Nelson LD, Mayer A, Huber DL, Harezlak J, Mathews VP, Ulmer JL, Sinson GP, Nencka AS, Koch KM, Wu YC, Saykin AJ, DiFiori JP, Giza CC, Goldman J, Guskiewicz KK, Mihalik J, Duma SM, Rowson S, Brooks A, Broglio SP, McAllister T, McCrea MA, Meier TB</p> <p>Identification and verification of ubiquitin-activated bacterial phospholipases Tessmer MH, Anderson DM, Pickrum AM, Riegert MO, Frank DW</p> <p>CD4+ T cell help is required for the formation of a cytolytic CD8+ T cell subset that protects against chronic infection and cancer Zander R, Schauder D, Xin G, Nguyen C, Wu X, Zajac A, Cui W</p>"},{"location":"pubs/#2018","title":"2018","text":"<p>The solution structure of CCL28 reveals structural lability that does not constrain antifungal activity Thomas MA, He J, Peterson FC, Huppler AR, Volkman BF</p> <p>mTORC1 and mTORC2 differentially promote natural killer cell development Yang C, Tsaih SW, Lemke A, Flister MJ, Thakar MS, Malarkannan S</p> <p>The importance of biologic knowledge and gene expression context for genomic data interpretation Zimmermann MT</p> <p>Region-based convolutional neural nets for localization of glomeruli in trichrome-stained whole kidney sections Bukowy JD, Dayton A, Cloutier D, Manis AD, Staruschenko A, Lombard JH, Woods LC, Beard DA, Cowley AW</p> <p>Resting-state functional connectivity after concussion is associated with clinical recovery Kaushal M, Espana LY, Nencka AS, Wang Y, Nelson LD, McCrea MA, Meier TB</p> <p>Transient receptor potential vanilloid 4 (TRPV4) activation by arachidonic acid requires protein kinase A-mediated phosphorylation Cao S, Anishkin A, Zinkevich NS, Nishijima Y, Korishettar A, Wang Z, Fang J, Wilcox DA, Zhang DX</p> <p>Simulating Airway Collapse in Obstructive Sleep Apnea using Fluid-Structure Interaction Methodologies Le TB, Garcia GJM</p>"},{"location":"pubs/#2017","title":"2017","text":"<p>Development and Validation of 2D Difference Intensity Analysis for Chemical Library Screening by Protein-Detected NMR Spectroscopy Egner JM, Jensen DR, Olp MD, Kennedy NW, Volkman BF, Peterson FC, Smith BC, Hill RB</p> <p>Metabolically Derived Lysine Acylations and Neighboring Modifications Tune the Binding of the BET Bromodomains to Histone H4 Olp MD, Zhu N, Smith BC</p>"},{"location":"pubs/#2016","title":"2016","text":"<p>Mechanism of Sirt1 NAD+-dependent Protein Deacetylase Inhibition by Cysteine S-Nitrosation Kalous KS, Wynia-Smith SL, Olp MD, Smith BC</p>"},{"location":"secure-computing/mfa-login/","title":"Logging in","text":"<p>ResHPC access requires a project user account, which is based on your MCW NetID and password. Your project username will be a combination of your NetID and a project identifier (example, jsmith.p12345). Your password and Duo MFA credentials are the same that you use to access Citrix and other MCW resources.</p> <p>Network Access</p> <p>ResHPC is available from Citrix and MCW-managed machines.</p>"},{"location":"secure-computing/mfa-login/#reshpc-ondemand","title":"ResHPC OnDemand","text":"<p>If you're new to using a cluster, ResHPC OnDemand offers web browser-based access. You can manage files and start a remote desktop session on the cluster. All of this is possible without logging in via a traditional SSH terminal.</p> <p>To login, point your browser to https://ood-reshpc.rcc.mcw.edu, enter your password, select a Duo MFA option, and complete the login.</p>"},{"location":"secure-computing/mfa-login/#ssh-connection","title":"SSH Connection","text":"<p>ResHPC login requires Duo MFA. For Windows users, we recommend a multi-factor compatible terminal client such as PuTTY. Mac and Linux users may use their OS provided terminal clients.</p> <p>To login, use the ResHPC login hostname <code>login-reshpc.rcc.mcw.edu</code>, enter your password, select a Duo MFA option, and complete the login process.</p> <p>Example login flow:</p> <pre><code>$ ssh jsmith.p12345@login-reshpc.rcc.mcw.edu\n(jsmith.p12345@login-reshpc.rcc.mcw.edu) Password:\n(jsmith.p12345@login-reshpc.rcc.mcw.edu) Duo two-factor login for jsmith\n\nEnter a passcode or select one of the following options:\n\n 1. Duo Push to XXX-XXX-XXXX\n 2. Phone call to XXX-XXX-XXXX\n 3. SMS passcodes to XXX-XXX-XXXX\n\nPasscode or option (1-3):\n</code></pre>"},{"location":"secure-computing/project-account/","title":"Accounts &amp; Projects","text":"<p>ResHPC access is based on projects. Each project corresponds to a protected dataset with a unique Data Use Agreement (DUA). For example, a PI may request a project to analyze a dbGaP dataset, with access determined by their original dbGaP DUA. Please note that only a MCW PI may establish a project.</p> <p>one DUA, one project</p> <p>Each ResHPC project is specific to a single DUA. If you have more than one DUA, you will need a separate project for each.</p>"},{"location":"secure-computing/project-account/#project-id","title":"Project ID","text":"<p>Each ResHPC project is identified within the environment by a unique project ID beginning with the letter p followed by a unique 5-digit code.</p>"},{"location":"secure-computing/project-account/#project-user-account","title":"Project User Account","text":"<p>ResHPC access requires a project user account, which is an extension of your MCW NetID (username) account. For example, you may be a member of project p12345, with project user account jsmith.p12345. For login, the project user account uses the same password and Duo 2FA authentication as the MCW NetID (jsmith in our example).</p> <p>Multiple users may have access to the same project, each with their own unique project user account (i.e. jsmith.p12345, bstevens.p12345, mbradley.p12345). A MCW investigator may also be a member of multiple projects, with multiple corresponding project user accounts (i.e. jsmith.p12345, jsmith.p23456, jsmith.p34567).</p>"},{"location":"secure-computing/project-account/#project-access","title":"Project Access","text":"<p>Project access and accounts are based on the project's DUA. For example, access to a project working with dbGaP data will only be granted to users that are part of the dbGaP DUA.</p> <p>To add a user to a project, first you must amend the DUA to include this user. Consult the data provider and/or MCW Grants &amp; Contracts for details.</p>"},{"location":"secure-computing/project-account/#getting-an-account","title":"Getting an Account","text":"<p>We strongly suggest to email help-rcc@mcw.edu prior to requesting or signing a DUA for a new dataset. Research Computing will not guarantee that ResHPC is suitable for your dataset.</p> <p>If you're ready to proceed, use the link below.</p> <p>Request a ResHPC Project Account</p>"},{"location":"secure-computing/project-storage/","title":"Project Storage","text":"<p>Each ResHPC project has project-specific storage directories in <code>/group/PINetID</code> and <code>/scratch/g/PINetID</code>, secured with a project-specific security group. Please note that ResHPC users do not have user scratch directories.</p> <p>For example, jsmith is PI for project p12345, with project directories <code>/group/jsmith/p12345</code> and <code>/scratch/g/jsmith/p12345</code>.</p> You can easily find your available project storage and current utilization with the <code>mydisks</code> command. <pre><code>$ mydisks\n=====My Storage=====\nSize  Used Avail Use% File\n 4.7G     0  4.7G   0% /home/user.p12345\n 932G  158G  774G  17% /group/PINetID/p12345\n 4.6T   62G  4.5T   2% /scratch/g/PINetID/p12345\n</code></pre>"},{"location":"secure-computing/project-storage/#encryption-requirement","title":"Encryption Requirement","text":"<p>Where noted below, encryption is required. This is an important step in ensuring security and integrity of restricted datasets.</p>"},{"location":"secure-computing/project-storage/#project-directory","title":"Project Directory","text":"<p>Quota: inherited from /group Snapshot: daily @ 2PM, 7 day lifetime Replication: continuous with snapshot</p> Each project has a unique directory located at <code>/group/{PINetID}/{ProjID}</code>. Within each project's <code>/group</code> directory, source and results data must be kept separate. You will find the following spaces in your <code>/group/{PINetID}/{ProjID}</code> directory: <p><code>source</code> - used for protected dataset from data provider</p> <p><code>results</code> - used for derivative results data and anything non-source</p> <p>Users must keep source and results separate. Most DUAs are time limited and Research Computing may be required to delete the restricted source dataset at project closeout. Keeping source and results separate will avoid forcing Research Computing to delete all of your project data.</p> <p>Encryption required</p> <p>Restricted source data must be encrypted, and remain encrypted when stored in the project's group directory.</p>"},{"location":"secure-computing/project-storage/#home-directory","title":"Home Directory","text":"<p>Quota: 5 GiB Snapshot: daily @ 12PM, 7 day lifetime Replication: continuous with snapshot</p> <p>Every project user account has a home directory located at <code>/home/{NetID}.{ProjID}</code>. The home directory is a requirement of hte cluster's Linux operating system. You should not store data in your home directory.</p> <p>Restricted data</p> <p>Storing restricted data in your home directory is prohibited.</p>"},{"location":"secure-computing/project-storage/#scratch-directory","title":"Scratch Directory","text":"<p>Quota: inherited from /scratch Purge: files may be deleted after 180 days</p> <p>Each project has a unique scratch directory located at <code>/scratch/g/{PINetID}/{ProjID}</code>. You may mix source and results files within your project scratch directory. However, you must delete all data in your scratch when your job is done.</p> <p>Encryption required</p> <p>Restricted source data may only be decrypted in the project's scratch directory, and only as needed for analysis. Do not leave unencrypted data in project's scratch directory. For example, if you're going on vacation, delete the unencrypted data.</p>"},{"location":"secure-computing/reshpc/","title":"ResHPC Overview","text":"<p>Restricted HPC (ResHPC) is a secure way to access and utilize the HPC cluster. It is specifically designed for restricted datasets that have a defined Data Use Agreement (DUA), including dbGaP projects. The ResHPC service is built on the existing HPC cluster, but incorporates a separate, secure login method, and project specific accounts and directories. With ResHPC, you can work with familiar tools while also satisfying complex data provider requirements.</p>"},{"location":"secure-computing/reshpc/#project-eligibility","title":"Project Eligibility","text":"<p>ResHPC is reserved for projects that need elevated security. Research Computing will evaluate every project request to ensure that ResHPC is required and meets security requirements. For projects with known security requirements, such as dbGaP, this process is simple and fast. For more complex projects, Research Computing will work with you and may require additional information and discussion. Please note that ResHPC does not meet the security standards for HIPAA compliance.</p> <p>We strongly suggest to email help-rcc@mcw.edu prior to requesting or signing a DUA for a new dataset. Research Computing will not guarantee that ResHPC is suitable for your dataset.</p>"},{"location":"secure-computing/reshpc/#training","title":"Training","text":"<p>ResHPC security training is mandatory for every user. Training is provided by appointment via Zoom. Projects with multiple users may schedule group training. ResHPC access will not be granted until completion of training.</p>"},{"location":"secure-computing/reshpc/#compliance","title":"Compliance","text":"<p>It is part of your role as data steward to comply with any DUA or related policies. Please note that utilizing ResHPC may not satisfy your compliance requirements. Research Computing is not responsible for your compliance.</p> <p>Read and understand policies and procedures.</p> <p>Failure to understand and adhere to your DUA, and applicable policy, could result in loss of data access and other punitive measures as determined by the institution.</p> <p>Helpful links:</p> <ul> <li>MCW dbGaP policy</li> </ul>"},{"location":"secure-computing/reshpc/#support","title":"Support","text":"<p>Please email questions to help-rcc@mcw.edu or attend regular office hours.</p> <p>Do not share restricted information</p> <p>Please avoid sharing restricted information in your help requests.</p>"},{"location":"secure-computing/software/","title":"Software","text":"<p>ResHPC uses the same software stack and module system as the HPC cluster. Users may request software by email to help-rcc@mcw.edu. A key difference is that ResHPC users are prohibited from installing their own software.</p> <p>For details on using modules, please see the modules guide.</p>"},{"location":"secure-computing/workflow/","title":"Running Jobs with Restricted Data","text":"<p>Job submission and management uses the same commands and syntax as the HPC cluster. The same partitions (queues), fairshare, and resource limits apply to jobs.  However, there are some key differences in workflow when using restricted datasets.</p> <p>Here we discuss running jobs, unique workflow features for ResHPC, and references to general documentation.</p>"},{"location":"secure-computing/workflow/#submitting-jobs","title":"Submitting Jobs","text":"<p>Job submission and management uses the same commands and syntax as the HPC cluster. However, ResHPC SLURM accounts are slightly different. When submitting a ResHPC job, the SLURM account is the project ID, not the PI's NetID.</p> <p>For details on submitting and managing SLURM jobs, please see Submitting SLURM Jobs.</p>"},{"location":"secure-computing/workflow/#encrypting-restricted-data","title":"Encrypting Restricted Data","text":"<p>Restricted source data must be encrypted, and remain encrypted when stored in the project's <code>/group</code> directory. Source data may only be decrypted after it is copied to the project's <code>/scratch</code> directory, and only as needed for analysis.</p> <p>Please note that many restricted datasets will be delivered to you in an encrypted format, such as dbGaP data. Some genomics software can work directly with these encrypted files. However, there are a variety of encryption programs available if needed.</p> <p>Please contact help-rcc@mcw.edu with questions.</p>"},{"location":"secure-computing/workflow/#data-staging-and-workflow","title":"Data Staging and Workflow","text":"<p>Staging data for a job is very similar to using the HPC cluster. A key difference is the need to encrypt restricted data when not in use.</p> <ol> <li>Copy encrypted data from project's <code>/group</code> source directory to <code>/scratch</code> directory.</li> <li>Decrypt files in project's <code>/scratch</code> directory and submits jobs that use the unencrypted data.</li> <li>Run jobs and copy results from <code>/scratch</code> directory back to project's <code>/group</code> results directory.</li> <li>Continue with further computations using the unencrypted data in project's <code>/scratch</code> directory.</li> <li>Finish workflow and delete files from project's <code>/scratch</code> directory.</li> </ol> <p>Warning</p> <p>Do not leave unencrypted data in project's <code>/scratch</code> directory. For example, if you're going on vacation, delete the unencrypted data.</p>"},{"location":"software/R/","title":"R","text":""},{"location":"software/R/#package-installation","title":"Package Installation","text":"<p>R uses a central package library that contains many common packages. The location of this library is <code>$R_HOME/library</code>. Users may also install their own packages locally. The default location for local package installation is <code>$HOME/R/x86_64-pc-linux-gnu-library/4.2</code>.</p> <p>Check first!</p> <p>Your package installation command will not check the centrally installed packages. You should always check if your package is already installed before proceeding.</p>"},{"location":"software/R/#user-package-install","title":"User Package Install","text":"<p>First load the R module:</p> <pre><code>module load R\n</code></pre> <p>Launch R:</p> <pre><code>R\n</code></pre> <p>Run the install command:</p> <pre><code>&gt; install.packages('SomePkg')\n</code></pre> <p>The first attempt will warn about writing to the central library. It will ask you to create and use a personal library. Answer yes to both.</p> <pre><code>Installing package into \u2018/hpc/apps/R/4.2.1/lib64/R/library\u2019\n(as \u2018lib\u2019 is unspecified)\nWarning in install.packages(\"ggplot2\") :\n'lib = \"/hpc/apps/R/4.2.1/lib64/R/library\"' is not writable\nWould you like to use a personal library instead? (yes/No/cancel) yes\nWould you like to create a personal library\n\u2018~/R/x86_64-pc-linux-gnu-library/4.2\u2019\nto install packages into? (yes/No/cancel) yes\n</code></pre> <p>Your package will be installed to your home directory. This package can be removed or updated using the standard R commands.</p>"},{"location":"software/R/#issues","title":"Issues","text":"<ul> <li>Some packages require system-wide packages or libraries in order to install correctly. If you see errors when you're installing a package, contact help-rcc@mcw.edu for assistance.</li> <li>The package manager does not check if the package is already installed centrally. If you install a package in your user directory, you may be installing a package that is already available. This is unnecessary use of space and resources. Always check if a package is already installed using the <code>library(package)</code> command.</li> </ul>"},{"location":"software/R/#request-package-install","title":"Request Package Install","text":"<p>Upon request, RCC will install or update R packages in the central library. As shown above, you may install your own packages and are not required to notify RCC. We do ask that if you need a package that currently or potentially has wide use at MCW, then please notify help-rcc@mcw.edu RCC to install centrally.</p>"},{"location":"software/R/#running-r-jobs","title":"Running R Jobs","text":"<p>R can be run in batch or interactive jobs. Please do not run long or resource intensive R scripts on the login node.  </p>"},{"location":"software/R/#small-interactive-jobs","title":"Small Interactive Jobs","text":"<p>Small interactive jobs include light plotting, simple analysis of small data sets, etc. These jobs never take more than one core, a few GB of memory, and never last more than a few minutes. These small, fast jobs are allowed on a  login node. However, use caution when running these jobs and double-check that they will not use larger resources. If you need to run an interactive R workflow that is more resource intensive, please use an interactive cluster job.</p> <p>To get an interactive session to run R on the cluster:</p> <pre><code>srun --ntasks=1 --mem-per-cpu=4GB --time=01:00:00 --job-name=interactive --pty bash\n</code></pre>"},{"location":"software/R/#multi-core-jobs","title":"Multi-core Jobs","text":"<p>Multi-core jobs should be run on the cluster compute nodes using the Torque queuing system. There are several options for running these jobs in Torque, including the Rscript command and the BatchJobs library. Both methods interface R with Torque, however, their use cases are different. The Rscript command should be used when you have written an R program .r file and would like to run this script on the cluster. The BatchJobs library should be used when you would like to test individual functions in a semi-interactive way and submit this work to the cluster.</p> <p>Example SLURM submission script:</p> R-test.slurm <pre><code>#!/bin/bash\n#SBATCH --job-name=R-test\n#SBATCH --ntasks=1\n#SBATCH --mem-per-cpu=1gb\n#SBATCH --time=00:01:00\n#SBATCH --output=%x-%j.out\n\nmodule load R/4.2.1\n\nRscript Rtest.r  \n</code></pre> <p>Submit the job:</p> <pre><code>sbatch myRtest.sh\n</code></pre>"},{"location":"software/R/#help","title":"Help","text":"<p>If you have questions about running R on the HPC cluster, please contact help-rcc@mcw.edu for assistance.</p>"},{"location":"software/matlab/","title":"MATLAB Parallel Server","text":"<p>The MATLAB Parallel Server software is an extension of the Parallel Computing Toolbox. The software runs on the HPC Cluster and can be used to run MATLAB jobs that are too large to run on your personal desktop/laptop computer. RCC has a license for 256 workers.</p>"},{"location":"software/matlab/#requirements","title":"Requirements","text":"<ul> <li>RCC user account</li> <li>MATLAB R2021b</li> </ul> <p>Desktop client</p> <p>To use MATLAB Parallel Server, your desktop client must be licensed through MCW.</p>"},{"location":"software/matlab/#installation","title":"Installation","text":"<p>MATLAB requires that the Parallel Server version match the client version. RCC attempts to update the MATLAB Parallel Server software whenever the central MCW license server is updated. The current version is R2021b. Please install the correct client version before proceeding with the Client-to-Cluster configuration.</p>"},{"location":"software/matlab/#configuration","title":"Configuration","text":"<ol> <li>Download the HPC Cluster setup files. Unzip and save this folder to a location of your choice. Please note, this folder is necessary for the cluster setup and should be saved in a location so that it will not be erased.</li> <li>Open outbound firewall ports '''14384-14448''' for the MATLAB program on your computer. This will require administrator privileges on your computer. Contact your department IT worker for assistance.</li> <li> <p>Save the following script as <code>startup.m</code> in a location on the MATLAB path that will not be deleted. :     === \"startup.m\"</p> <pre><code>% startup.m\n% Startup script identifies available interfaces, \n% and selects correct interface.\n\ne = java.net.NetworkInterface.getNetworkInterfaces();\nwhile(e.hasMoreElements())\nee = e.nextElement().getInetAddresses();\nwhile (ee.hasMoreElements())\ni = ee.nextElement().getHostAddress().toString();\nif contains(i,java.lang.String('141.106'))\npctconfig('hostname',char(i));\nend\nend\nend\n</code></pre> </li> <li> <p>Launch the MATLAB application and navigate to Home &gt; Parallel &gt; Create and Manage Clusters.</p> </li> <li>Open the Cluster Profile Manager and select Import.</li> <li>Browse to the location of the MATLAB_R2021b_Client2Cluster folder and select the HPC_Cluster.mlsettings file.</li> <li>Select the profile in the Cluster Profile Manager and click Edit. Scroll down to the Scheduler Plugin section of the profile and change the PluginScriptsLocation property to point to the location of your copy of the MATLAB_R2021b_Client2Cluster folder. Locate the Additional Properties table. Edit the RemoteJobStorageLocation and Username properties by replacing NetID with your MCW username.</li> <li>Select the HPC Cluster profile in the Cluster Profile Manager and select the Validation tab. Change the Number of workers to use to 1. Select Validate. Enter your MCW password. All tests should pass.</li> <li>Finally select the profile in the Cluster Profile Manager and select Set as Default.</li> </ol>"},{"location":"software/matlab/#upgrading","title":"Upgrading","text":"<p>RCC will periodically update the MATLAB Parallel Server software to the next B version.</p> <p>To update, first desktop software to match the new cluster version. Then follow the steps above to configure the new version. Please note that your client software must be equal version or older than cluster version.</p>"},{"location":"software/matlab/#using-the-cluster","title":"Using the Cluster","text":"<p>There are several ways to interact with the cluster using the Parallel Computing Toolbox. The parpool and batch commands can be used to create jobs to run your code on the cluster. Examples are provided below. More information is available on the Mathworks website for Batch Processing and Parpool.</p>"},{"location":"software/matlab/#batch","title":"Batch","text":"<p>The batch command also creates a pool of workers in a job on the cluster. It creates a remote pool of workers on the cluster that can run your script when workers are available. In comparison to the parpool option option, the batch command does not require that you wait for a pool of workers. Instead, your script is submitted to the cluster to be run in a batch pool when workers are available.</p>"},{"location":"software/matlab/#number-of-workers","title":"Number of Workers","text":"<p>The batch command can be submitted as a pool job, where N is the number of workers.</p> <pre><code>&gt;&gt; job = batch('mytest','Pool',N)\n</code></pre>"},{"location":"software/matlab/#job-time","title":"Job Time","text":"<p>Each batch job is submitted to the HPC cluster with default max walltime of 7 days There are times (near maintenance windows) that this may not work for every job. You can add a unique time limit to your job by using AdditionalSubmitArgs.</p> <pre><code>&gt;&gt; % Select cluster\n&gt;&gt; c = parcluster(\"HPC Cluster\");\n&gt;&gt; % Set time\n&gt;&gt; c.AdditionalProperties.AdditionalSubmitArgs = '--time=DD-HH:MM:SS';\n&gt;&gt; % Start batch job\n&gt;&gt; job = batch(c,\"mytest\");\n</code></pre> <p>A specific time limit can be added to any job. Max time is 7 days. For example, a job with a 10 hour time limit would set c.AdditionalProperties.AdditionalSubmitArgs = '--time=10:00:00';.</p>"},{"location":"software/matlab/#documentation","title":"Documentation","text":"<p>Please review the MathWorks tutorial explaining batch parallel jobs:</p>"},{"location":"software/matlab/#parpool","title":"Parpool","text":"<p>The parpool command creates a pool of workers in a job on the cluster. It creates an interactive session using remote cluster nodes to run the pool of workers. The parpool command does require that enough workers are available on the cluster before the pool will start. If you do not need to run commands interactively, and/or have your code in a script, please try the batch example.</p>"},{"location":"software/matlab/#number-of-workers_1","title":"Number of Workers","text":"<p>The parpool command can be submitted with variable pool size, where N is the number of workers. Please try to use parpool sizes that are multiples of 12.</p> <pre><code>&gt;&gt; parpool(N)\n</code></pre>"},{"location":"software/matlab/#job-time_1","title":"Job Time","text":"<p>Each parpool job is submitted to the HPC cluster with default max walltime of 7 days There are times (near maintenance windows) that this may not work for every job. You can add a unique time limit to your job by using AdditionalSubmitArgs.</p> <pre><code>&gt;&gt; % Select cluster\n&gt;&gt; c = parcluster(\"HPC Cluster\");\n&gt;&gt; % Set time\n&gt;&gt; c.AdditionalProperties.AdditionalSubmitArgs = '--time=DD-HH:MM:SS';\n&gt;&gt; % Open a pool of 12 workers on the cluster\n&gt;&gt; p = c.parpool(12);\n</code></pre> <p>A specific time limit can be added to any job. Max time is 7 days For example, a job with a 10 hour time limit would set c.AdditionalProperties.AdditionalSubmitArgs = '--time=10:00:00';.</p>"},{"location":"software/matlab/#start-pool","title":"Start Pool","text":"<p>To start a parpool on default cluster with N workers:</p> <pre><code>&gt;&gt; parpool(N);\n</code></pre> <p>To start parpool on HPC Cluster with N workers:</p> <pre><code>&gt;&gt; parpool('HPC Cluster',N);\n</code></pre> <p>Start a parpool object on a cluster with N workers and attach a file myfile.m:</p> <pre><code>&gt;&gt; poolobj = parpool('HPC Cluster',N);\n&gt;&gt; addAttachedFiles(poolobj,{'mytest.m'});\n</code></pre>"},{"location":"software/matlab/#run-code","title":"Run Code","text":"<p>Now that the parpool is started, you can run your code. The code can be run interactively or using a script.</p> <p>To run code interactively:</p> <pre><code>&gt;&gt; parfor i = 1:1024\n&gt;&gt;   A(i) = sin(i*2*pi/1024);\n&gt;&gt; end\n</code></pre> <p>Plot output:</p> <pre><code>&gt;&gt; plot(A);\n</code></pre> <p>To run code with a script, create a new script:</p> mytest.m <pre><code>parfor i = 1:1024\nA(i) = sin(i*2*pi/1024);\nend\n</code></pre> <p>Execute script:</p> <pre><code>&gt;&gt; mytest\n</code></pre> <p>Plot output:</p> <pre><code>&gt;&gt; plot(A)\n</code></pre>"},{"location":"software/matlab/#shutdown-pool","title":"Shutdown Pool","text":"<p>Please make sure to shutdown your parpool when you're done computing. To use gcp to shutdown your parpool:</p> <pre><code>&gt;&gt; delete(gcp(poolobj))\n</code></pre>"},{"location":"software/matlab/#file-transfer-and-management","title":"File Transfer and Management","text":"<p>The Matlab Parallel Computing Toolbox has multiple ways to handle file transfrer and access. For small files, the files can be auto-attached and transfer to the remote cluster at job submission. However, if your workflow requires large files, the transfer at job time becomes inconvenient. In this case, it is better to transfer files to the cluster before job submission, see File Transfer. For more information about using data in Batch jobs, please see Share Code with the Workers.</p>"},{"location":"software/matlab/#cluster-usage-policy","title":"Cluster Usage Policy","text":"<p>The HPC Cluster is a shared resource. Please only use whatever resources are needed for your computation. When you're done, please make sure to stop your processes and close any batch or parpool jobs. This is especially important to ensure that fair access is maintained.</p>"},{"location":"software/matlab/#getting-help","title":"Getting Help","text":"<p>Review Mathwork's Batch Processing and Parpool documentation.</p> <p>If you have questions/concerns please contact help-rcc@mcw.edu</p>"},{"location":"software/module-request/","title":"Requesting Software","text":"<p>All RCC users are eligible to request software installation. Read on to find out how we evaluate requests, and how to submit a request.</p>"},{"location":"software/module-request/#submitting-a-request","title":"Submitting a Request","text":"<p>To submit a software installation request, please email help-rcc@mcw.edu with the following information:</p> <ol> <li>Name of the software</li> <li>Link to the software files</li> <li>Link to the software documentation</li> <li>Brief description of need</li> </ol> <p>RCC will evaluate the software based on your request. This process is much faster if the above information is included in the original request.</p>"},{"location":"software/module-request/#installation","title":"Installation","text":"<p>RCC will evaluate your request to determine how to install the software. If approved, we will install the software in the <code>/hpc/apps</code> directory. Not all software requests will be centrally installed. For example, many R and Python packages can be installed without admin privileges. In that case, RCC admins would provide the proper installation command.</p>"},{"location":"software/module-request/#paid-license-software","title":"Paid License Software","text":"<p>Some software packages require a paid license. Paid license software packages have additional requirements that RCC must evaluate. Often this includes what type of license (not all paid license types are supported), and other contractual terms that MCW must abide.</p> <p>In order to avoid issues, please contact help-rcc@mcw.edu to setup a time to discuss your proposed installation. Please note that the PI funding the software purchase must attend this meeting.</p> <p>Do not buy software for the cluster without talking to RCC first.</p> <p>RCC does not guarantee that your software can or will be installed on the cluster. It is up to you to contact RCC prior to purchasing the software. Failure to do so may result in delays and/or denial of installation.</p>"},{"location":"software/modules/","title":"Software Modules","text":"<p>We use Lmod to manage installed software. Each software package installed on the cluster has a corresponding modulefile, which contains information about an application's version, executable, libraries, and documentation. Using the module commands, users can add, remove, or switch versions of an application.</p>"},{"location":"software/modules/#module-help","title":"Module Help","text":"<p>Print help information for module command:</p> <pre><code>module help\n</code></pre> <p>Print help information for a module:</p> <pre><code>module help [modulefile]\n</code></pre>"},{"location":"software/modules/#show-loaded-modules","title":"Show Loaded Modules","text":"<p>Show currently loaded modules:</p> <pre><code>module list\n</code></pre>"},{"location":"software/modules/#show-available-modules","title":"Show Available Modules","text":"<p>Show currently available modules:</p> <pre><code>module avail\n</code></pre> <p>This will output a list of modules that represent installed software.</p>"},{"location":"software/modules/#show-module-information","title":"Show Module Information","text":"<p>Print information about a module:</p> <pre><code>module show [modulefile]\n</code></pre> <p>Print module contents:</p> <pre><code>module display [modulefile]\n</code></pre>"},{"location":"software/modules/#load-module","title":"Load Module","text":"<p>Add a module to the user environment:</p> <pre><code>module load [modulefile]\n</code></pre> <p>Example:</p> <pre><code> module load gcc\n</code></pre> <p>Adds the GCC compiler to the user environment.</p>"},{"location":"software/modules/#unload-module","title":"Unload Module","text":"<p>Remove a module from the user environment:</p> <pre><code>module unload [modulefile]\n</code></pre> <p>Example:</p> <pre><code>module unload gcc\n</code></pre> <p>Removes the GCC compiler from the user environment.</p>"},{"location":"software/modules/#swap-modules","title":"Swap Modules","text":"<p>Swap a loaded module for another module:</p> <pre><code>module swap [modulefile1] [modulefile2]\n</code></pre>"},{"location":"software/python/","title":"Python","text":"<p>Summary</p> <p>Here we present several ways to use and customize your Python environment. As you will see, there are multiple ways to achieve the same goal. Some are more elaborate and time consuming, but also offer more choice in customization. It will be up to you to decide which solution best suits your needs. However, a few ideas here may help you along the way. We'll discuss the following methods starting with the simplest and increasing in difficulty and depth of customization.</p> <p>The fastest way to start installing and using your own Python packages is to follow the Installing Packages guide. You will be able to install, uninstall, and start using packages quickly. If you're looking for a testing environment, you should try Python Virtual Environments. Virtualenvs allow you to quickly setup a reusable container that can be started, stopped, and easily deleted if needed. Best of all, you can have as many separate Python virtualenvs as you'd like. Finally, you may find that a package or script requires Python itself to be installed with some custom options. This can be done without system administrator privileges using the custom local Python guide.</p> <p>Python is an excellent programming and data analysis tool that is widely used in many areas of computational science. You'll find many ways to solve problems as we've shown here. If you have any questions about Python, please contact help-rcc@mcw.edu.</p> <p>Python2 Deprecated</p> <p>Python2 is deprecated. The developers are no longer maintaining the source code. It is recommended that all users migrate their scripts from Python2 to Python3. At the least, users should not write new scripts in for Python2.</p>"},{"location":"software/python/#using-installed-python","title":"Using Installed Python","text":"<p>The HPC cluster includes Python3.9 and Intel Python3. Use <code>module avail python</code> to see available versions. Python2.7 is deprecated but installed for backwards compatibility. You should not use it for any new scripting.</p> <p>To use Python3:</p> <pre><code>module load python/3.9.1 \npython\n</code></pre> <p>To use Intel Python3:</p> <pre><code>module load python/intel-2021.1\npython\n</code></pre>"},{"location":"software/python/#list-installed-packages","title":"List Installed Packages","text":"<p>Many common scientific Python packages (i.e., NumPy, SciPy, Pandas) are already installed.</p> <p>To view all installed packages:</p> <pre><code>module load python/3.9.1\npip freeze\n</code></pre> <p>To search for a specific package (e.g., SciPy):</p> <pre><code>pip freeze | grep 'scipy'\n</code></pre>"},{"location":"software/python/#installing-packages","title":"Installing Packages","text":"<p>Most packages can be installed in your home directory without any assistance from a system administrator. This allows you to maintain a set of local packages, built on top of the central Python installation.</p> <p>To install packages to your home directory:</p> <pre><code>module load python/3.9.1 \npip install --user myPackage </code></pre> <p>The <code>--user</code> flag installs packages to a default directory <code>~/.local/bin</code> in your home directory.</p> <p>Then add your local Python package directory to your <code>$PATH</code> variable. Edit your <code>~/.bashrc</code> file and add the following:</p> <pre><code>PATH=~/.local/bin:$PATH\nexport PATH\n</code></pre> <p>Then source your updated setting:</p> <pre><code>source ~/.bashrc\n</code></pre>"},{"location":"software/python/#python-virtual-environment","title":"Python Virtual Environment","text":"<p>Users can install any Python package using <code>virtualenv</code>, which creates a virtual environment within your home directory. A Python virtual environment allows a user to locally install any package using traditional Python package installation methods. For more information on Python virtual environments, see the Virtualenv User Guide.</p>"},{"location":"software/python/#setup","title":"Setup","text":"<p>To get started with Python <code>virtualenv</code>, load a Python modulefile:</p> <pre><code>module load python/3.9.1 </code></pre> <p>Create a new virtual environment:</p> <pre><code>virtualenv myPython39venv\n</code></pre> <p>The <code>virtualenv</code> command automatically creates a new directory (e.g., myPython39venv). It then installs Python and the necessary packages setuptools, pip, and wheel.</p> <p>To use your Python virtual environment:</p> <pre><code>source myPython39venv/bin/activate\n</code></pre> <p>To exit your Python virtual environment:</p> <pre><code>deactivate </code></pre>"},{"location":"software/python/#installing-packages_1","title":"Installing Packages","text":"<p>Packages can be installed in a Python virtual environment using <code>pip</code> or <code>setup.py</code>.</p> <p>To install a package using <code>pip</code>:</p> <pre><code>pip install numpy\n</code></pre> <p>The <code>pip</code> command will install packages (e.g., NumPy to the site-packages directory in your virtual environment. Installed packages can be listed with the <code>pip freeze</code> command.</p> <p>Packages from the system-wide Python installations can also be included in your Python virtual environment. This must be done when creating the virtual environment.</p> <p>To create and use a Python virtual environment with system-wide packages:</p> <pre><code>virtualenv --system-site-packages Python39withSysPkgs\nsource Python39withSysPkgs/bin/activate\n...\n</code></pre> <p>The Python virtual environment (e.g., Python39withSysPkgs) now includes all packages from the system-wide Python3.6. The <code>pip freeze</code> command shows the list of packages. You could now install new packages as shown above, creating a virtual extension to the system-wide Python installations.</p>"},{"location":"software/python/#miniconda-python","title":"Miniconda Python","text":"<p>Miniconda is a lightweight installation of Anaconda. It is built on the conda package manager and includes many relevant scientific computing packages. The HPC Cluster has Miniconda3 installed.</p> <p>For more information, see Conda Docs.</p> <p>Installing your own Conda</p> <p>If you install your own Conda, this will often modify your <code>.bashrc</code> file. This will cause your base Conda env to load every time you login. This is very useful if you're working on your own Linux machine. But it is very un-useful on a cluster, where we also use modulefiles to load software. In fact, your Conda installation can cause your jobs to fail in many instances. If you would like to use Conda, then please use the centrally installed Miniconda3. If you must use your own Conda, please turn off the auto activate with <code>conda config --set auto_activate_base false</code>. You can then manually activate your Conda with <code>source /path/to/my/conda/etc/profile.d/conda.sh &amp;&amp; conda activate</code>.</p>"},{"location":"software/python/#use-miniconda-python","title":"Use Miniconda Python","text":"<pre><code>module load miniconda3\npython\n</code></pre>"},{"location":"software/python/#virtual-environments","title":"Virtual Environments","text":"<p>Create a new virtual environment (e.g., myenv with the <code>conda</code> command:</p> <pre><code>conda create -n myenv\n</code></pre> <p>To use your Miniconda virtual environment:</p> <pre><code>source activate myenv\n</code></pre>"},{"location":"software/python/#installing-packages_2","title":"Installing Packages","text":"<p>To install packages in your conda virtual environment:</p> <pre><code>module load miniconda3\nsource activate myenv\nconda install numpy\n</code></pre>"},{"location":"software/python/#python-in-a-job-script","title":"Python in a Job Script","text":"<p>You may want to use your personal Python environment in a SLURM job on the cluster. Please review the Writing a Job Script guide before proceeding. The following examples show various methods to use your personal Python environment.</p> py-venv.slurmconda-venv.slurm <pre><code>#!/bin/bash\n#SBATCH --job-name=Python\n#SBATCH --ntasks=1\n#SBATCH --mem-per-cpu=1gb\n#SBATCH --time=00:01:00\n#SBATCH --output=%x-%j.out\n\nmodule load python/3.9.1\nsource myPython36venv/bin/activate\npython myPythonScript.py\n</code></pre> <pre><code>#!/bin/bash\n#SBATCH --job-name=Miniconda\n#SBATCH --ntasks=1\n#SBATCH --mem-per-cpu=1gb\n#SBATCH --time=00:01:00\n#SBATCH --output=%x-%j.out\n\nmodule load miniconda3\nsource activate myenv\npython myPythonScript.py\n</code></pre>"},{"location":"software/pytorch/","title":"PyTorch","text":"<p>PyTorch can be run in batch, interactive, or Jupyter Notebook. For more information, check the module help information with <code>module help pytorch</code>.</p>"},{"location":"software/pytorch/#pytorch-job","title":"PyTorch job","text":"<p>The following example will use PyTorch to train a network on the MNIST data set.</p> <p>First, download the PyTorch examples:</p> <pre><code>git clone https://github.com/pytorch/examples.git\n</code></pre> <p>Now that you have the examples, use the following job script to train the network.</p> pytorch-mnist.slurm <pre><code>#!/bin/bash\n#SBATCH --job-name=pytorch\n#SBATCH --ntasks=1\n#SBATCH --time=01:00:00\n#SBATCH --account={PI_NetID}\n#SBATCH --partition=gpu\n#SBATCH --gres=gpu:1\n#SBATCH --output=%x-%j.out\n\nmodule load pytorch\npython examples/mnist/main.py &gt;&gt; output.log  \n</code></pre> <p>Submit the job:</p> <pre><code>cd /scratch/u/netid/pytorch-test &amp;&amp; sbatch pytorch.sh\n</code></pre>"},{"location":"software/pytorch/#pytorch-jupyter-notebook","title":"PyTorch Jupyter Notebook","text":"<p>This functionality is now provided by Open OnDemand!</p> <p>See Jupyter on Open OnDemand for more info.</p>"},{"location":"software/schrodinger/","title":"Schrodinger","text":"<p>Schrodinger is licensed by the Department of Biochemistry and available to all MCW investigators.</p> <p>Users interested in contributing funds or discussing Schrodinger licensing at MCW should contact Dawn Wenzel and Brian Smith.</p> <p>The Schrodinger Small-Molecule Drug Discovery Suite includes a GUI client that you can run on your Windows, Mac, or Linux desktop/laptop. This client can be configured to send jobs to the HPC Cluster. Example use includes molecular modeling, docking, molecular dynamics simulation, etc. See below for installation.</p>"},{"location":"software/schrodinger/#requirements","title":"Requirements","text":"<ul> <li>RCC user account</li> </ul>"},{"location":"software/schrodinger/#installation-configuration","title":"Installation &amp; Configuration","text":"<ol> <li>Download 2023-1 software from https://www.schrodinger.com and run the installer.</li> <li> Locate the schrodinger.hosts file. Windows <code>$INSTALLDIR\\Schrodinger 2023-1\\schrodinger.hosts</code> Mac <code>/opt/schrodinger/suites2023-1/schrodinger.hosts</code> </li> <li> <p>Download the server schrodinger.hosts file. Add the text from the downloaded file to your schrodinger.hosts file (you located in step #2). Replace NetID with your MCW username and save the file.</p> </li> <li> <p>Open the Configure Licensing tool and select I can identify my license server from the Add Licenses drop-down menu. Locate the hostname and port in the licensing info. Click Save Server. If you see a remote license server warning, this can be ignored.</p> <p>Warning</p> <p>The license server hostname has changed. If you used Schrodinger prior to 2023, you will need to update your client with the new license information.</p> </li> <li> Setup remote connection to the cluster. Windows Open the <code>Remote Login Configuration</code> tool. Select <code>Generate Keys</code>. Select <code>Initialize Host Access</code>. Enter the host IP Address (this is in your schrodinger.hosts file) and your MCW username. Select <code>Initialize</code>. Mac Configure password-less SSH for remote login. Open a terminal and follow this guide. </li> <li> <p>Launch the Maestro application.</p> </li> </ol>"},{"location":"software/schrodinger/#upgrading","title":"Upgrading","text":"<p>To upgrade your Schrodinger installation, first uninstall the current version. The uninstall process should leave your configuration intact. Then install the upgraded version of Schrodinger and remember to update your schrodinger.hosts file as it appears above. If you have issues upgrading, please contact help-rcc@mcw.edu.</p>"},{"location":"software/schrodinger/#usage","title":"Usage","text":"Included in your install are configurations for the remote server connection to HPC Cluster. These settings are used as follows: <p>server_cpu - HPC Cluster connection for Schrodinger CPU jobs</p> <p>server_gpu - HPC Cluster connection for Schrodinger GPU jobs</p> <p>When running Schrodinger jobs, please follow these guidelines:</p> <ul> <li> <p>Run all pre-processing jobs on the localhost (your machine).</p> </li> <li> <p>Run docking, MD, etc. jobs with remote connection to HPC Cluster.</p> </li> </ul>"},{"location":"software/schrodinger/#schrodinger-command-line","title":"Schrodinger Command-Line","text":"<p>Some Schrodinger scripts are not included in the Maestro interface and must be run from the command line. See Schrodinger scripts for a complete list and details.</p> <p>To see the options for a particular script.py on the cluster:</p> <pre><code>/hpc/apps/schrodinger/2023-1/run script.py -h\n</code></pre> <p>To run the script in a job on the cluster, adapt the following job submission script to your specific command:</p> schrod.slurm <pre><code>#!/bin/bash\n#SBATCH --job-name=test_job\n#SBATCH --ntasks=1\n#SBATCH --time=01:00:00\n#SBATCH --output=%x-%j.out\n\n/hpc/apps/schrodinger/2023-1/run script.py\n</code></pre>"},{"location":"software/schrodinger/#troubleshooting","title":"Troubleshooting","text":"<p>Schrodinger can be sensitive to changes in networking. This is often an issue for laptop users. You may see errors such as:</p> <ul> <li>Launch failed: no JobId found.</li> <li>WARNING: You did not specify for -maxjob. Remember its default value is 1.</li> </ul> <p>In this case, you should reset your connection to the Schrodinger server using the following steps.</p> <p>Mac OS X only</p> <p>This solution works on Mac OS X and assumes that you have installed Schrodinger 2023-1. Modify the version number if you have an older version installed.</p> <p>On your laptop/desktop:</p> <ul> <li>Shutdown Schrodinger.</li> <li>Open terminal and run the following commands:</li> </ul> <pre><code>/opt/schrodinger/suites2023-1/utilities/jserver -shutdown\n/opt/schrodinger/suites2023-1/utilities/jserver -cleanall\n/opt/schrodinger/suites2023-1/utilities/jserver -proxy -shutdown\n/opt/schrodinger/suites2023-1/utilities/jserver -proxy -cleanall\n</code></pre> <p>On the cluster:</p> <ul> <li>Run the following commands:</li> </ul> <pre><code>/hpc/apps/schrodinger/2023-1/utilities/jserver -shutdown\n/hpc/apps/schrodinger/2023-1/utilities/jserver -cleanall\n/hpc/apps/schrodinger/2023-1/utilities/jserver -proxy -shutdown\n/hpc/apps/schrodinger/2023-1/utilities/jserver -proxy -cleanall\n</code></pre>"},{"location":"software/schrodinger/#help","title":"Help","text":"<p>Having issues installing? Contact help-rcc@mcw.edu to schedule a support session.</p> <p>For general Schrodinger questions, see https://www.schrodinger.com/kb.</p> <p>For training opportunities, see https://www.schrodinger.com/seminars/current and https://www.schrodinger.com/training.</p>"},{"location":"software/singularity/","title":"Singularity","text":""},{"location":"software/singularity/#overview","title":"Overview","text":"<p>Singularity is a container solution designed for high-performance computing systems. A Singularity container is a collection of application and dependency files, which is packaged as a single portable image file. Containers are independent from the host operating system, allowing applications that are not natively supported to run on a variety of HPC resources. They are conceptually similar to Docker, but focus more on HPC. Singularity containers can be shared and distributed to support reproducible research and can be run on most HPC systems without modification as long as Singularity is installed.</p>"},{"location":"software/singularity/#singularity-commands","title":"Singularity Commands","text":"<p>Singularity uses a series of subcommands and options controlled by a wrapper script called <code>singularity</code>. The <code>-h</code> option displays the command-line help documentation:</p> <pre><code>$ module load singularity\n$ singularity -h\nUSAGE: singularity [global options...] &lt;command&gt; [command options...] ...\n\nGLOBAL OPTIONS:\n    -d|--debug    Print debugging information\n    -h|--help     Display usage summary\n    -s|--silent   Only print errors\n    -q|--quiet    Suppress all normal output\n       --version  Show application version\n    -v|--verbose  Increase verbosity +1\n    -x|--sh-debug Print shell wrapper debugging information\n\nGENERAL COMMANDS:\n    help       Show additional help for a command or container                  selftest   Run some self tests for singularity install                      \n\nCONTAINER USAGE COMMANDS:\n    exec       Execute a command within container                               run        Launch a runscript within container                              shell      Run a Bourne shell within container                              test       Launch a testscript within container                           \n\nCONTAINER MANAGEMENT COMMANDS:\n    apps       List available apps within a container                           bootstrap  *Deprecated* use build instead                                   build      Build a new Singularity container                                check      Perform container lint checks                                    inspect    Display container's metadata                                     mount      Mount a Singularity container image                              pull       Pull a Singularity/Docker container to $PWD                      \n\nCOMMAND GROUPS:\n    image      Container image command group                                    instance   Persistent instance command group                                \n\n\nCONTAINER USAGE OPTIONS:\n    see singularity help &lt;command&gt;\n</code></pre> <p>For more information see the Singularity Quick Start.</p>"},{"location":"software/singularity/#download-pre-built-containers","title":"Download Pre-built Containers","text":"<p>Many software packages already have containers built by other users. These containers are available from external sites such as Singularity Hub or Docker Hub.</p> <p>The <code>singularity pull</code> command is used to download existing containers.</p>"},{"location":"software/singularity/#pull-from-singularity-hub","title":"Pull from Singularity Hub","text":"<p>To download a container from Singularity Hub:</p> <pre><code>$ singularity pull shub://vsoch/hello-world \nProgress |===================================| 100.0%\nDone. Container is at: /home/user/vsoch-hello-world-master.sif\n$ ./vsoch-hello-world-master.sif\nRaawwWWWWWRRRR!!\n</code></pre> <p>You can also download and rename containers:</p> <pre><code>$ singularity pull --name myContainer.sif shub://vsoch/hello-world\nProgress |===================================| 100.0%\nDone. Container is at: /home/user/myContainer.sif\n$ ./myContainer.sif\nRaawwWWWWWRRRR!!\n</code></pre>"},{"location":"software/singularity/#pull-from-docker-hub","title":"Pull from Docker Hub","text":"<p>To download a container from Docker Hub:</p> <pre><code>$ singularity pull docker://godlovedc/lolcow\nWARNING: pull for Docker Hub is not guaranteed to produce the\nWARNING: same image on repeated pull. Use Singularity Registry\nWARNING: (shub://) to pull exactly equivalent images.\nDocker image path: index.docker.io/godlovedc/lolcow:latest\nCache folder set to /home/user/.singularity/docker\n[6/6] |===================================| 100.0%\nImporting: base Singularity environment\nImporting: /home/user/.singularity/docker/sha256:9fb6c798fa41e509b58bccc5c29654c3ff4648b608f5daa67c1aab6a7d02c118.tar.gz\n...\nBuilding Singularity image...\nSingularity container built: ./lolcow.img\nCleaning up...\n$ ./lolcow.img\n ________________________________________\n/ It is a wise father that knows his own \\\n| child.                                 |\n|                                        |\n| -- William Shakespeare, \"The Merchant  |\n\\ of Venice\"                             /\n ----------------------------------------\n        \\   ^__^\n         \\  (oo)\\_______\n            (__)\\       )\\/\\\n||----w |\n||     ||\n</code></pre> <p>The pull command downloads the container from Docker, converts it to Singularity format, and builds a the container. This is different than pulling an image from Singularity Hub, where the pull command simply downloads the image. Singularity includes warnings about this fact. Since a pull from Docker Hub induces a build process, the downloaded container is not guaranteed to be the same each time. If strict reproducibility is needed, pull from Singularity Hub.</p>"},{"location":"software/singularity/#build-from-singularity-hub","title":"Build from Singularity Hub","text":"<p>The <code>singularity build</code> command can also be used to download existing containers.</p> <pre><code>$ singularity build hello-world.sif shub://vsoch/hello-world\nCache folder set to /home/user/.singularity/shub\nProgress |===================================| 100.0%\nBuilding from local image: /home/user/.singularity/shub/vsoch-hello-world-master.sif\nBuilding Singularity image...\nSingularity container built: hello-world.sif\nCleaning up...\n$ ./hello-world.sif\nRaawwWWWWWRRRR!!\n</code></pre> <p>When using the build command, you must specify a name for your container. The build command differs from pull in that it will download and then build your image using the latest Singularity image format. Additional functionality of the build command is discussed in Build a Container.</p>"},{"location":"software/singularity/#build-from-docker-hub","title":"Build from Docker Hub","text":"<pre><code>$ singularity build lolcow.sif docker://godlovedc/lolcow\nDocker image path: index.docker.io/godlovedc/lolcow:latest\nCache folder set to /home/user/.singularity/docker\nImporting: base Singularity environment\nImporting: /home/user/.singularity/docker/sha256:9fb6c798fa41e509b58bccc5c29654c3ff4648b608f5daa67c1aab6a7d02c118.tar.gz\n...\nBuilding Singularity image...\nSingularity container built: lolcow.sif\nCleaning up...\n$ ./lolcow.sif\n ______________________________________ \n&lt; Today is what happened to yesterday. &gt;\n --------------------------------------\n        \\   ^__^\n         \\  (oo)\\_______\n            (__)\\       )\\/\\\n||----w |\n||     ||\n</code></pre>"},{"location":"software/singularity/#build-a-container","title":"Build a Container","text":"<p>The primary function of the build command is to create new containers either from scratch or based on existing containers. It is also used to convert between container formats. Full documentation of the build command is available at Singularity Docs. Here we include an example definition file and build process for a Python container.</p>"},{"location":"software/singularity/#definition-file","title":"Definition File","text":"<p>First we write a definition file for the new container. A definition file defines the container build process including software installation, runtime functionality, etc. This file can be named how you like, but it is recommended to denote definition files with the <code>.def</code> extension. We will call our definition file <code>Python.def</code>.</p> container.def <pre><code>Bootstrap: docker\nFrom: ubuntu:20.04\n\n%help\n# Add information describing your container.\nThis container includes Python.\n\n%environment\n    # Set useful environment variables here. This section is used only at runtime, not during build.\nexport PATH=/opt/python/bin:$PATH\nexport LD_LIBRARY_PATH=/opt/python/lib:$LD_LIBRARY_PATH\n\n%post\n    # Add build commands here. These commands are only run at build time.\n\n# Create useful bind points for needed file systems. The following are set by default in RCC and should always be included for containers used in RCC.\nmkdir -p /scratch /hpc\n\n    # Install necessary packages.\napt-get update &amp;&amp; apt-get install -y --no-install-recommends \\\nbuild-essential \\\ngcc-multilib \\\nca-certificates \\\nzlib1g-dev \\\nlibssl-dev \\\ncurl\n    apt-get clean\n    rm -rf /var/lib/apt/lists/*\n\n    # Install Python from source.\nexport PATH=/opt/python/bin:$PATH\ncurl https://www.python.org/ftp/python/2.7.15/Python-2.7.15.tgz -o Python-2.7.15.tgz\n    tar -xvf Python-2.7.15.tgz &amp;&amp; cd Python-2.7.15\n    ./configure --prefix=/opt/python &amp;&amp; make &amp;&amp; make install\n    rm -rf Python-2.7.15*\n\n    # Install pip package manager.\ncurl https://bootstrap.pypa.io/get-pip.py | python\n\n    # Install some useful Python packages.\npip install --upgrade numpy scipy matplotlib \n\n%test\n    /opt/python/bin/python --version\n</code></pre> <p>Full documentation of definition files at Singularity Docs.</p>"},{"location":"software/singularity/#build","title":"Build","text":"<p>Build the container using the definition file:</p> <pre><code>sudo singularity build Python.sif Python.def\n</code></pre> <p>Build requires <code>root</code> or <code>sudo</code> permissions. The syntax is always <code>singularity build</code> followed by the new container name, denoted by the <code>.sif</code> extension, and the definition file.</p>"},{"location":"software/singularity/#test","title":"Test","text":"<p>Copy your container file to your RCC home directory and run a test:</p> <pre><code>$ srun --ntasks=1 --mem-per-cpu=4GB --time=01:00:00 --job-name=interactive --account={PI_NetID} --pty bash\n$ module load singularity\n$ singularity exec Python.sif python --version\nPython 2.7.15\n</code></pre> <p>Here we print the version of Python installed in the container. The exec command executes a command (i.e., <code>python --version</code>) within the container.</p>"},{"location":"software/singularity/#containers-in-jobs","title":"Containers in Jobs","text":"<p>Singularity containers were designed to be run on HPC systems. RCC maintains containers for several software packages on the clusters. The following examples show an RCC built Singularity container which can be run in an interactive or batch job.</p>"},{"location":"software/singularity/#example-interactive-job","title":"Example Interactive job","text":"<p>Start an interactive job on the cluster:</p> <pre><code>srun --ntasks=1 --mem-per-cpu=4GB --time=01:00:00 --job-name=interactive --account={PI_NetID} --pty bash\n</code></pre> <p>Load the Singularity module:</p> <pre><code>module load singularity\n</code></pre> <p>Run a command in your container:</p> <pre><code>$ singularity exec Python.sif python hello_world.py\nHello, World!\n</code></pre> <p>The exec command is used to execute the <code>hello_world.py</code> script within the container.</p> <p>Alternatively, shell into the container and run a command:</p> <pre><code>$ singularity shell Python.sif \nSingularity: Invoking an interactive shell within container...\n\nSingularity Python.sif:~&gt; python hello_world.py \nHello, World!\n</code></pre> <p>If your container has a %runscript section defined, then you could also use the <code>singularity run</code> command. Choose the method that works best for you.</p>"},{"location":"software/singularity/#example-batch-job","title":"Example Batch Job","text":"container.sh <pre><code>#!/bin/bash\n#SBATCH --job-name=Testing\n#SBATCH --ntasks=1\n#SBATCH --time=00:01:00\n#SBATCH --account=&lt;PI_NetID&gt;\n#SBATCH --output=%x-%j.out\n\nmodule load singularity\nsingularity exec Python.sif python hello_world.py\n</code></pre> <p>Submit the job:</p> <pre><code>sbatch container.sh\n</code></pre> <p>This job will execute the <code>hello_world.py</code> script within the <code>Python.sif</code> container on a compute node. The output file should contain <code>Hello, World!</code>.</p>"},{"location":"software/singularity/#singularity-on-rcc","title":"Singularity on RCC","text":"<p>RCC uses Singularity to install and maintain software packages that would not otherwise be available on the compute clusters. This is often due to incompatible libraries or unsupported operating system. In some cases Singularity is used to control access or functionality of an application. RCC-built containers are designed to interact with RCC clusters. They include necessary file mount points, special libraries (e.g., CUDA), and custom wrapper commands. Here we will discuss the elements needed to make your containers compatible with RCC systems.</p> <p>A set of useful directories are mounted by default on RCC clusters. The following file mounts should be included for non-GPU containers:</p> <pre><code>/hpc\n/scratch\n</code></pre> <p>Add to the <code>%post</code> section of your definition file:</p> <pre><code>mkdir -p /hpc /scratch\n</code></pre>"},{"location":"software/singularity/#singularity-and-docker","title":"Singularity and Docker","text":"<p>Singularity is conceptually similar to Docker and easily supports Docker images. We've shown above that Singularity can be used to download and Singularity-ize Docker images. It can also be used to build containers starting from a Docker image base (RCC does this). This allows RCC to support a wide variety of software that is already containerized with Docker. If you can find a container on Docker Hub, chances are that it will be supported through Singularity. If you already use Docker to containerize your software, then you can continue developing in Docker knowing that Singularity will easily import your images.</p> <p>Full information on Singularity and Docker at Singularity Docs.</p>"},{"location":"software/singularity/#getting-help","title":"Getting Help","text":"<p>Contact help-rcc@mcw.edu for assistance with containers.</p>"},{"location":"software/tensorflow/","title":"TensorFlow","text":"<p>TensorFlow on HPC can be run in batch, interactive, or Jupyter Notebook.</p>"},{"location":"software/tensorflow/#tensorflow-interactive-job","title":"TensorFlow interactive job","text":"<p>Start the job.</p> <pre><code>srun --job-name=tensorflow --ntasks=1 --time=1:00:00 --gres=gpu:1 --pty bash\n</code></pre> <p>Load the TensorFlow module.</p> <pre><code>module load tensorflow\n</code></pre> <p>Start your training or other commands.</p> <pre><code>python train.py options input output\n</code></pre> <p>When your commands end, always remember to end the interactive job.</p> <pre><code>exit\n</code></pre>"},{"location":"software/tensorflow/#tensorflow-batch-job","title":"TensorFlow batch job","text":"<p>This is an example of running a Python script in a SLURM batch job.</p> learning-ml.pylearning-ml.slurm <pre><code>import tensorflow as tf\nhello = tf.constant('Hello, TensorFlow!')\nsession = tf.Session()\ntf.print(hello)\n</code></pre> <pre><code>#!/bin/bash\n#SBATCH --job-name=learning\n#SBATCH --ntasks=1\n#SBATCH --time=00:01:00\n#SBATCH --account={PI_NetID}\n#SBATCH --partition=gpu\n#SBATCH --gres=gpu:1\n#SBATCH --output=%x-%j.out\n\nmodule load tensorflow\npython /scratch/u/user/learning-ml.py &gt;&gt; output.log  \n</code></pre> <p>Save these scripts to your scratch directory, and submit the job:</p> <pre><code>sbatch learning-ml.slurm\n</code></pre> <p>This simple job should print Hello, TensorFlow! to your output file.</p>"},{"location":"software/tensorflow/#tensorflow-jupyter-notebook-job","title":"TensorFlow Jupyter Notebook job","text":"<p>This functionality is provided by Open OnDemand!</p> <p>See Jupyter on Open OnDemand for details.</p>"},{"location":"software/tensorflow/#tensorboard-job","title":"TensorBoard Job","text":"<p>This functionality is provided by Open OnDemand!</p>"},{"location":"storage/data-access/","title":"Mounting Drives","text":"<p>Research Computing group storage is also available via an SMB mount on your Windows or Mac desktop. This access is convenient, but cannot be used to access files that you have saved via your cluster access. In other words, you can save and utilize data via your cluster access (Linux), or via this access (Windows), but the data cannot be accessed from both.</p> <p>Contact help-rcc@mcw.edu to request Windows access to your storage space.</p>"},{"location":"storage/data-access/#mount-a-windows-drive","title":"Mount a Windows Drive","text":"<p>Microsoft provides a helpful guide. In step #4, please make sure to type in your drive path, which will be in the form <code>\\\\qfs2.rcc.mcw.edu\\pi_netid</code>. Do not select Browse. Use your MCW username and password when prompted.If you are not on an MCW-owned or managed machine, please make sure to preface your MCW username with <code>mcwcorp\\</code>.</p> <p>If you are having trouble remounting your drive, please first right-click on the drive and select disconnect. If the drive disconnects successfully, then try to remount, but make sure to select Connect using different credentials. Please contact help-rcc@mcw.edu if the issue persists.</p>"},{"location":"storage/data-sharing/","title":"Sharing Data","text":"<p>Your lab group storage can be used to collaborate with non-lab members. This is done with by-request project directories. For example, if lab <code>pi</code> would like to collaborate with some data for a project called <code>zephyr</code>, then the lab PI would contact RCC to create a project directory.</p> <pre><code>$ ls -l /group/pi\ntotal 8\ndrwxrws---. 3 root sg-pi-zephyr 512 Mar 26 13:52 zephyr\ndrwxrws---. 4 root sg-pi       1024 May 19 14:04 work\n</code></pre> <p>In addition to the usual <code>work</code> directory, there is now a <code>zephyr</code> project directory, which is controlled by the <code>sg-pi-zephyr</code> security group. Project data would go in that directory, and any number of collaborators (MCW researchers) can be added to the security group.</p>"},{"location":"storage/file-cleanup/","title":"File Cleanup &amp; Archiving","text":"<p>There are several tools and commands available to help you manage your data, including finding large directories that you can compress down or delete if no longer needed.  Keeping your directories free of old or unwanted files will help keep your account under your disk usage quota.</p>"},{"location":"storage/file-cleanup/#check-storage-quota-limits","title":"Check Storage Quota Limits","text":"<p>You can easily find your available storage directories and current utilization on the clusters with the <code>mydisks</code> command.</p> <pre><code>$ mydisks\n=====My Lab=====\nSize  Used Avail Use% File\n47G   29G   19G  61% /home/user\n932G  158G  774G  17% /group/pi\n4.6T     0  4.6T   0% /scratch/g/pi \n</code></pre>"},{"location":"storage/file-cleanup/#finding-large-files-and-directories","title":"Finding Large Files and Directories","text":"<p>Several tools exist to help identify file size and type. Here we discuss use of <code>du</code>.</p> <p>To list the top 20 files/directories, sorted by size:</p> <pre><code>du -ah . | sort -n -r | head -n 20\n</code></pre> <p>Another variation of the du command to show directories and their sizes:</p> <pre><code>du -h --max-depth=1\n</code></pre>"},{"location":"storage/file-cleanup/#compressing-and-archiving-directories","title":"Compressing And Archiving Directories","text":"<p>So now you have identified some folders that you don't immediately need.  You can compress and archive those directories or files using <code>tar</code> and <code>gzip</code>.</p> <p>To recursively compress every file and directory inside the path you specify:</p> <pre><code>tar -czvf name-of-archive.tar.gz /path/to/directory-or-file\n</code></pre> <p>The <code>tar</code> command has many switches. We used the most common set in the previous command:</p> <pre><code>-c Create an archive.  \n-z Compress the archive with gzip.  \n-v Display progress in the terminal while creating the archive, also known as \u201cverbose\u201d mode.  \n-f Allows you to specify the filename of the archive.\n</code></pre> <p>If you have a directory called myproject in your current home directory that you want to compress and archive, you can run the following.</p> <pre><code>tar -czvf myproject.tar.gz myproject\n</code></pre> <p>You can also use the tar command to check the contents of your archive. The following will print a list of directories and files in the archive.</p> <pre><code>tar -tf myproject.tar.gz\n</code></pre> <p>Once you are satisfied with your archive, you can then delete the original directory using <code>rm</code>.</p> <pre><code>rm -rf myproject\n</code></pre> <p>USE CAUTION!</p> <p>Most deletions in Linux are permanent.</p> <p>If sometime down the road, you need to access the content of directory myproject again, you can extract the archive by running this command.</p> <pre><code>tar -xzvf myproject.tar.gz\n</code></pre> <p>The <code>-x</code> flags tells tar to extract.  Once the command completes, you will now have the folder myproject available in your current directory.</p>"},{"location":"storage/file-cleanup/#creating-a-file-manifest","title":"Creating a file manifest","text":"<p>When archiving a dataset, it is often helpful to have a full manifest, or list, of the original file hierarchy. A file manifest is also a key piece of metadata.</p> <p>To list files in an .tar.gz achive:</p> <pre><code>tar -tf myarchive.tar.gz\n</code></pre> <p>To create a manifest file of the listing, run the same command, but pipe it to a text file:</p> <pre><code>tar -tf myarchive.tar.gz &gt; myarchive.manifest\n</code></pre>"},{"location":"storage/file-cleanup/#managing-archive-file-size","title":"Managing archive file size","text":"<p>Some file archives can be quite large. If you're uploading your archive to a repository, there may be a max single file upload size. In this case it is useful to split the archive file into smaller chunks.</p> <p>To split a <code>.tar.gz</code> archive into smaller chunksize:</p> <pre><code>split -b 500M myarchive.tar.gz \"myarchive.tar.gz.part\"\n</code></pre> <p>Now you should have a set of 500M files.</p> <p>To join the file chunks and recreate the full archive:</p> <pre><code>cat myarchive.tar.gz.parta* &gt; myarchive.tar.gz.joined\n</code></pre>"},{"location":"storage/file-permissions/","title":"File Permissions","text":"<p>Proceed with caution</p> <p>When modifying file permissions in Linux, use caution and take time to fully understand the effect of your proposed permission changes. Errant permission changes can make a file unusable by yourself, or others.</p> <p>Users may want to modify file/directory permissions to enable sharing. This should only be done in spaces that are meant for sharing. Each lab has shared group and scratch directories with inherited group permissions. Never modify permissions to open your home directory for sharing.</p> <p>If you need group write permission for a file (not recommended in Linux):</p> <pre><code>chmod g+w /path/to/file\n</code></pre> <p>Here we add the <code>w</code> write permission, for <code>g</code> group.</p> <p>Why is group write not recommended?</p> <p>Linux does not include group write permission by default, even in your shared lab spaces. This protects users. For instance, if multiple users attempt to edit the same file, collisions may occur and there is a high risk the file would be corrupted and information lost. Again, group write permissions are not recommended. It is much better for each user to make their own copy of a file.</p> <p>If you'd like to add write permissions on a directory and its files, add the <code>-R</code> recursive flag:</p> <pre><code>chmod -R g+w /group/PI_NetID/work/path/to/directory\n</code></pre> <p>You can check permissions before and after with command <code>ls -l /group/PI_NetID/work/path/to/file</code>.</p>"},{"location":"storage/file-permissions/#advanced","title":"Advanced","text":"<p>Additional utilities are available to help you manage your file permissions. Here we'll highlight the <code>find</code> utility for locating and managing file objects.</p> <p>To add group write permissions on all files in the current directory:</p> <pre><code>find . -type f -exec chmod g+w {} \\;\n</code></pre> <p>To add group write permissions on all directories in the current directory:</p> <pre><code>find . -type d -exec chmod g+w {} \\;\n</code></pre>"},{"location":"storage/file-recovery/","title":"File Recovery","text":"<p>This procedure will not work in every case!</p> <p>Sometimes a file is created and deleted before a snapshot can be completed. For example, home directories are snapshotted once daily. If you cannot locate your file with the following procedures, contact help-rcc@mcw.edu.</p>"},{"location":"storage/file-recovery/#linux-all-clusters","title":"Linux (All Clusters)","text":"<p>To recover files in a directory, access the <code>.snapshot</code> directory. Snapshot directories are numbered with the largest number being the latest snapshot. However, if you would like to see the time points, use command <code>ls -l</code>.</p> <pre><code>ls -l .snapshot/\n# snapshots listed with timestamp\ndrwx------. 92 user sg-pi 73728 May 20 12:00 543_Home Directory_homefs\ndrwx------. 92 user sg-pi 73728 May 21 12:00 545_Home Directory_homefs\ndrwx------. 92 user sg-pi 73728 May 22 12:00 547_Home Directory_homefs\ndrwx------. 92 user sg-pi 73728 May 23 12:00 549_Home Directory_homefs\ndrwx------. 92 user sg-pi 73728 May 24 12:00 551_Home Directory_homefs\ndrwx------. 92 user sg-pi 73728 May 25 12:00 553_Home Directory_homefs\ndrwx------. 92 user sg-pi 73728 May 26 12:00 555_Home Directory_homefs\n</code></pre> <p>Once you select a snapshot directory, you can navigate to your files. Then copy back the file you need.</p> <pre><code>cp /home/user/.snapshot/555_Home Directory_homefs/file1 /home/user\n</code></pre> <p>Commands must reference <code>.snapshot</code> directly.</p> <p>The <code>.snapshot/</code> directory is hidden from standard Linux tools. Consider the following example:</p> <pre><code>ls -la /home/user # will not show .snapshot/\nls -la /home/user/.snapshot/ # displays the contents of .snapshot/\n</code></pre>"},{"location":"storage/file-recovery/#windows","title":"Windows","text":"<p>To recover a file in your Windows share:</p> <ol> <li>Open the folder that previously contained your lost file.</li> <li>Right-click in the window and select Properties.</li> <li>Select the Previous Versions tab.</li> <li>Select the version you would like to explore.</li> <li>In the new window, locate the file you want to recover.</li> <li>Copy the file or folder to the previous location.</li> </ol>"},{"location":"storage/file-recovery/#help","title":"Help","text":"<p>Remember, snapshots are timestamped. Look for the timestamped version that may contain your file. For instance, if you deleted a file Tuesday, then try a timestamped version from Monday. Contact help-rcc@mcw.edu with questions.</p>"},{"location":"storage/file-transfer/","title":"File Transfer","text":"<p>Several methods are available for transferring data to/from the HPC Cluster. These include Open OnDemand, command-line, and desktop client software. RCC recommends Open OnDemand for all users, especially for remote work.</p>"},{"location":"storage/file-transfer/#open-ondemand","title":"Open OnDemand","text":"<p>Open OnDemand is a web portal for using HPC and includes a file management app. For more information, see Open OnDemand Files App.</p>"},{"location":"storage/file-transfer/#command-line","title":"Command-line","text":"<p>Several command-line options are available for secure data transfer.</p>"},{"location":"storage/file-transfer/#scp","title":"scp","text":"<p>Secure copy (scp) is a tool for secure data transfer between UNIX-like systems using your MCW username and password. Available on Linux and Mac OS X. All commands should be run from the command-line in a terminal app on your computer.</p> <p>File to HPC Cluster:</p> <pre><code>scp local_file user@login-hpc.rcc.mcw.edu:/path/to/remote/target-directory\n</code></pre> <p>Directory to HPC Cluster:</p> <pre><code>scp -r local_directory user@login-hpc.rcc.mcw.edu:/path/to/remote/target-directory\n</code></pre> <p>File from HPC Cluster:</p> <pre><code>scp user@login-hpc.rcc.mcw.edu:/path/to/remote_file /path/to/local/target-directory\n</code></pre> <p>Directory from HPC Cluster:</p> <pre><code>scp -r user@login-hpc.rcc.mcw.edu:/path/to/remote_directory /path/to/local/target-directory\n</code></pre>"},{"location":"storage/file-transfer/#rsync","title":"rsync","text":"<p>Remote sync (rsync) is a fast and secure data transfer tool. Available on Linux and Mac OS X. All commands should be run from the command-line in a terminal app on your computer.</p> <p>File to HPC Cluster:</p> <pre><code>rsync -avz local_file user@login-hpc.rcc.mcw.edu:/path/to/target-directory\n</code></pre> <p>Directory to HPC Cluster:</p> <pre><code>rsync -avz local_directory user@login-hpc.rcc.mcw.edu:/path/to/target-directory\n</code></pre> <p>File from HPC Cluster:</p> <pre><code>rsync -avz  user@login-hpc.rcc.mcw.edu:/path/to/remote_file /path/to/local/target-directory\n</code></pre> <p>Directory from HPC Cluster:</p> <pre><code>rsync -avz  user@login-hpc.rcc.mcw.edu:/path/to/remote_directory /path/to/local/target-directory\n</code></pre>"},{"location":"storage/file-transfer/#desktop-clients","title":"Desktop Clients","text":"<p>Several software packages are available for data transfer using the secure file transfer protocol (SFTP).</p>"},{"location":"storage/file-transfer/#winscp","title":"WinSCP","text":"<p>WinSCP is a popular SFTP client for Windows.</p>"},{"location":"storage/file-transfer/#cyberduck","title":"Cyberduck","text":"<p>Cyberduck is a secure data transfer client available for Windows and Mac OS X users.</p>"},{"location":"storage/mcw-storage/","title":"Additional Storage Options","text":"<p>MCW offers multiple campus-wide storage options.</p>"},{"location":"storage/mcw-storage/#mcw-is-storage","title":"MCW-IS Storage","text":"<p>Most users with MCW-owned or managed machines will recognize this storage as a <code>H:\\</code> or <code>G:\\</code> drive on their Windows computer. This storage is free and backed up, but limited in size and performance, and meant for productivity data, i.e., documents, spreadsheets, etc. Please do not store raw research data. Contact MCW-IS help desk with questions.</p>"},{"location":"storage/mcw-storage/#box-and-onedrive","title":"Box and OneDrive","text":"<p>Every MCW user has a finite amount of free space available on Box and OneDrive. Both solutions are cloud based, and utilize your MCW credentials for access. These solutions are suitable for productivity data, i.e., documents, spreadsheets, presentations, etc. Please do not store raw research data. In addition, both have a max file upload sizes, and an option to share data. Contact MCW-IS help desk with questions.</p>"},{"location":"storage/mcw-storage/#electronic-lab-notebook","title":"Electronic Lab Notebook","text":"<p>Each electronic lab notebook has a finite amount of space available and a max single file upload size. ELN is free to all users, but should not be considered a primary storage system. ELN should be used to store data that would normally be stored in a paper notebook, or supplemental storage. Data sharing is possible.</p>"},{"location":"storage/paid-storage/","title":"Paid Additional Storage","text":""},{"location":"storage/paid-storage/#overview","title":"Overview","text":"<p>Additional <code>/group/pi_netid</code> storage is available through a paid Research Group Storage (RGS) subscription.</p>"},{"location":"storage/paid-storage/#subscription-cost","title":"Subscription Cost","text":"<p>The cost is $60/TiB/year. All fees must be prepaid. Minimum subscription size is 1TiB. Minimum subscription duration is 1 year or the number of months until the start of the next calendar year. RGS subscriptions are based on calendar year (January 1 to December 31). Subscriptions purchased in mid-year will be charged a prorated fee according to the number of months until January 1. RCC will not refund RGS fees for any reason.</p>"},{"location":"storage/paid-storage/#unpaid-fees","title":"Unpaid Fees","text":"<p>If RGS fees are unpaid, RCC admins will change your storage directory to read-only (i.e. no new data can be written). The PI will have until March 31 to pay any fees that are due or move the data off of RGS.</p>"},{"location":"storage/paid-storage/#ownership","title":"Ownership","text":"<p>The RGS service is a subscription-based lease of storage space for a finite duration. RCC retains ownership of all hardware associated with RGS.</p>"},{"location":"storage/paid-storage/#availability","title":"Availability","text":"<p>Storage availability is not guaranteed. Requests for subscription greater than 50TiB will require RCC review.</p>"},{"location":"storage/paid-storage/#sign-up-payment","title":"Sign-up &amp; Payment","text":"<p>A RCC account is required for RGS. If you do not already have an RCC account, submit a request. RCC will then process your account and provision the storage. If you are not a PI, your PI must also have an RCC account.</p> <p>Payment can be made through the MCW-IS service desk website using the following guide.</p> <ol> <li>Proceed to https://servicedesk.mcw.edu and login.</li> <li>Select RCC Software, then Research Group Storage - 1TiB.</li> <li>To pay for 1TiB, select Add to Cart. If you are paying for multiple TiBs, select Add Multiple and enter the quantity.</li> <li>Finally, select Place Your Order and enter your 16-17 Digit Account Number.</li> </ol> <p>Questions?</p> <p>If you have questions about your quota limit, please email help-rcc@mcw.edu. If you have questions about the self-service payment process, please contact the MCW-IS help desk.</p>"},{"location":"storage/rcc-storage/","title":"Storage Overview","text":"<p>Research Computing provides storage in two tiers meant to support both large scale and high performance. Every MCW lab is eligible for a limited amount of free storage. For many labs, this amount of free storage is sufficient for their research. For labs with large data needs, additional storage is available for fee.</p> <p>All storage is connected via high speed link to the cluster and available via Linux command-line, SFTP, or Open OnDemand. In addition, some storage is available directly to users via Windows or NFS shares.</p> You can easily find your available storage paths and current utilization on the cluster  with the <code>mydisks</code> command. <pre><code>$ mydisks\n=====My Lab=====\nSize  Used Avail Use% File\n47G   29G   19G  61% /home/user\n932G  158G  774G  17% /group/pi\n4.6T     0  4.6T   0% /scratch/g/pi\n</code></pre>"},{"location":"storage/rcc-storage/#storage-paths","title":"Storage Paths","text":""},{"location":"storage/rcc-storage/#home","title":"Home","text":"<p>Quota: 50 GiB Snapshot: daily @ 12PM, 7 day lifetime Replication: continuous with snapshot</p> <p>Every user has a home directory located at <code>/home/netid</code>. The home directory is used for storing user-installed software, user-written scripts, etc. Each home directory is only accessible by its owner. This directory is not suitable for sharing files. The quota limit is 50GiB.</p>"},{"location":"storage/rcc-storage/#group","title":"Group","text":"<p>Quota: 1 TiB, paid additional Snapshot: daily @ 2PM, 7 day lifetime Replication: continuous with snapshot</p> <p>Every lab is eligible for a group directory at <code>/group/pi_netid</code> with a free 1TiB limit. This space is meant for research data in active projects. This space is large scale, but low performance. It is not meant for high I/O, and so is not mounted to compute nodes.</p> <p>Additional storage capacity may be purchased through our Research Group Storage service in 1TiB increments for $60/TiB/year. Please see Paid Additional Storage for details.</p>"},{"location":"storage/rcc-storage/#scratch","title":"Scratch","text":"<p>Quota: 5 TiB, expandable to 10 TiB Purge: files may be deleted after 180 days</p> <p>Scratch space is intended for data that is read/written during jobs running on the cluster. It is located on all compute nodes at <code>/scratch</code>. Every user has a directory at <code>/scratch/u/netid</code> with quota limit 5TiB. Every group has a directory at <code>/scratch/g/pi_netid</code> with quota limit 5TiB. Scratch space may be increased by request with justification.</p> <p>Do you need more scratch storage?</p> <p>Scratch storage may be increased beyond the 5TiB limit. To increase scratch storage, send an email to help-rcc@mcw.edu with the amount and justification.</p>"},{"location":"storage/rcc-storage/#local-scratch","title":"Local Scratch","text":"<p>Quota: No quota, limited to size of disk (440GiB) Purge: files deleted after every job</p> <p>Local scratch disk may be the fastest computing option to store your job runtime files, especially for jobs that are heavily I/O dependent (i.e. lots of files are read/written). However, it does take some time to transfer your files from your global scratch directory to local scratch, and the space is limited (440GiB).</p>"},{"location":"storage/rcc-storage/#permissions","title":"Permissions","text":"<p>Every lab storage path will have an associated security group consisting of the PI and additional users that the PI adds. We require two points of contact that are authorized to request permissions changes. The PI will serve as one point of contact and will provide an alternate. Any group permission changes must come from the PI or alternate. Requests must be made through the MCW ticketing system.</p>"},{"location":"storage/rcc-storage/#restrictions","title":"Restrictions","text":"<p>The following types of data are strictly prohibited on Research Computing systems:</p> <ul> <li> <p>Any data that would violate the MCW Code of Conduct, MCW Corporate Polices, or any applicable data-use agreement (i.e. IRB, federal grant regulations, etc.)</p> </li> <li> <p>Any data that is subject to HIPAA</p> </li> </ul>"},{"location":"storage/rcc-storage/#data-protection","title":"Data Protection","text":"<p>All Research Computing storage systems are highly resilient, allowing for multiple disk and server failures without losing data. We also maintain support contracts for all storage with provisions for prompt hardware replacement. In addition, some file systems have additional protection/features.</p> <p>Disclaimer</p> <p>Research Computing is not responsible for any loss of data. We strongly encourage all users to follow best practice data management strategies.</p>"},{"location":"storage/ref-data/","title":"Reference Data","text":"<p>RCC maintains a reference data space on the cluster that is available to all users. It is located at <code>/hpc/refdata</code>. The purpose of this space is to provide central access to commonly used data. This allows users to save space and share a common reference dataset. RCC will also download or build reference data and connect it to applications when possible.</p> <p>Users may request to add reference data by contacting help-rcc@mcw.edu.</p>"},{"location":"storage/ref-data/#examples","title":"Examples","text":"<p>The following are examples of reference data that RCC currently hosts. This is not a complete list.</p> <p><code>/hpc/refdata/blast/2.9.0</code> <code>/hpc/refdata/bowtie2/hg19</code> <code>/hpc/refdata/gatk</code> <code>/hpc/refdata/hisat2/Ensembl_GRCh38</code> </p>"},{"location":"user-guide/accounts/","title":"Getting an Account","text":"<p>A user account is required for access to Research Computing resources, including the clusters. To obtain RCC access, you must be a PI or sponsored by a PI, and have an active MCW account. A PI may sponsor students, postdoctoral fellows, staff, or colleagues with whom they are collaborating on research. Please note, a PI sponsor must have an active RCC account.</p> <p>Info</p> <p>For RCC purposes, a PI is a full-time MCW faculty member.</p> <p>Request an Account</p>"},{"location":"user-guide/accounts/#terms-of-use","title":"Terms of Use","text":"<p>You agree at signup</p> <p>These terms are presented to you when you sign-up for an RCC account. By requesting an account and utilizing RCC resources, you are agreeing to these terms.</p>"},{"location":"user-guide/accounts/#terms-for-all-users","title":"Terms for All Users","text":"<ol> <li>I will not store data on Research Computing systems that would violate the MCW Code of Conduct, MCW Corporate Policies, or any applicable data-use agreement (i.e. IRB, federal grant regulations, etc.).</li> <li>I will not store data on Research Computing systems that is subject to HIPAA.</li> <li>I will ensure that security, access, and use of my data on Research Computing systems is maintained in compliance with any agreements or regulations associated with said data. This includes, but is not limited to, applicable MCW policies, IRB agreements, data use agreements, and funding agency regulations.</li> <li>In the event that Research Computing ceases to provide the HPC environment, Research Group Storage, or a comparable resource, I will transfer my data to other storage resources within the provided time window.</li> </ol>"},{"location":"user-guide/accounts/#additional-terms-for-pi","title":"Additional Terms for PI","text":"<ol> <li>I take full responsibility for ensuring that all users in my permissions group will adhere to the terms provided by Research Computing regarding their use of Research Computing systems.</li> <li>I acknowledge that I am responsible for the Research Computing systems related actions of all users in my permissions group.</li> <li>I acknowledge that Research Computing does not provide backup of data stored on Research Computing systems.</li> <li>I acknowledge that Research Computing is not responsible for loss of my data resulting from hardware failure, unforeseen catastrophic events, and/or software failure.</li> <li>I acknowledge that I am responsible for the security of my data stored on Research Computing systems.</li> </ol>"},{"location":"user-guide/etiquette/","title":"User Etiquette","text":"<p>RCC clusters are shared resources. Please be respectful of your computational neighbors and adhere to the following guidelines.</p>"},{"location":"user-guide/etiquette/#guidelines","title":"Guidelines","text":"<ol> <li> <p>All jobs must be run through the queueing system.</p> <p>For the cluster to work properly as a shared resource, all jobs must go through the queueing system.</p> </li> <li> <p>Do not start computationally intensive work on cluster login nodes.</p> <p>Login nodes are designed for user logins, managing jobs, and accessing data storage. All three of those services must work for the cluster to function. If you start intensive computing on a login node, you may cause some or all of those services to fail or the node itself to fail, resulting in lost work for you and others.</p> </li> <li> <p>User login to compute nodes is prohibited.</p> <p>Any processing on a compute node that is done outside the queueing system can cause the node to fail. Simply put, if you\u2019re not supposed to be computing there, you don\u2019t need to be logged in.</p> </li> <li> <p>Be accurate with your resource requests.</p> <p>Do not request more resources than are needed to complete your job. Most jobs are not parallel. Requesting multiple cores when your job cannot use them wastes resources that might be used by other users. This is a very common problem! Do your best and ask for help if you're unsure.</p> </li> </ol>"},{"location":"user-guide/etiquette/#enforcement","title":"Enforcement","text":"<p>Each login node has a safety mechanism built-in to prevent a user from crashing the server or other users' processes. This per-user limit is 4 CPU cores and 20 GB memory. When a user is at or above their limit, the system will throttle their processes. Users will receive email messages when violations occur.</p> <p>Intensive computing on a login node is prohibited.</p> <p>If a command requires more than 1 core, then it should be submitted in a job to the scheduler. The 4 core limit is a safety mechanism to prevent accidentally crashing a login node, not an approval to run a small computational workflow.</p>"},{"location":"user-guide/quickstart/","title":"Cluster Quick Start","text":"<p>This guide contains the minimal steps to get started running computational workflows, with links to further reading included. If you're a first time user, please follow the links and review the full documentation.</p> <p>Need help getting started? Send us an email at help-rcc@mcw.edu.</p>"},{"location":"user-guide/quickstart/#getting-an-account","title":"Getting an account","text":"<p>You need an RCC account to get started. Please see the Accounts guide for details.</p>"},{"location":"user-guide/quickstart/#logging-in","title":"Logging in","text":"<p>Login is available both on and off campus via SSH and Open OnDemand. Please see the Login guide for details.</p> <p>Clusters are shared resources.</p> <p>Please be respectful of all other users. Do not start resource-intensive scripts on a login node. Do not request more resources than your job can use. For more info see User Etiquette.</p>"},{"location":"user-guide/quickstart/#cluster-storage","title":"Cluster Storage","text":"<p>Your account has access to a set of storage directories by default. You can easily find your available storage paths and current utilization on the cluster with the <code>mydisks</code> command. Please see the storage guide for details.</p> <pre><code>$ mydisks\n=====My Lab=====\nSize  Used Avail Use% File\n47G   29G   19G  61% /home/user\n932G  158G  774G  17% /group/pi\n4.6T     0  4.6T   0% /scratch/g/pi\n</code></pre>"},{"location":"user-guide/quickstart/#transferring-files","title":"Transferring Files","text":"<p>Most users will need to transfer files to cluster storage. Several methods are available depending on your need. These include Open OnDemand, SSH (command-line), and desktop client software. Please see the file transfer guide for details.</p>"},{"location":"user-guide/quickstart/#using-software","title":"Using Software","text":"<p>Software is managed by modules using Lmod. The modules contain information about an application's version, executable, libraries, and documentation. Using module commands, users can add, remove, or switch versions of a application. Please see the cluster software guide for more information.</p>"},{"location":"user-guide/quickstart/#running-a-slurm-job","title":"Running a SLURM Job","text":"<p>The clusters use SLURM to manage jobs. Most jobs are scheduled using batch job scripts. A batch job script includes a request for cluster resources, and the commands to run in the job. Each batch job is submitted by the user for remote execution on a compute node. The SLURM scheduler decides where the job should run, based on the requested and available resources. Please see the SLURM job guide for details.</p>"},{"location":"user-guide/quickstart/#write-a-job-script","title":"Write a job script","text":"<p>The SLURM job script syntax is shown below. Just like previous clusters, every job needs a job script, which tells the scheduler how and when to run your workload. The following is a simple SLURM batch job script example.</p> test-job.slurm <pre><code>#!/bin/bash\n#SBATCH --job-name=test-job\n#SBATCH --ntasks=1\n#SBATCH --mem-per-cpu=1gb\n#SBATCH --time=00:01:00\n#SBATCH --account=PI_NetID\n#SBATCH --output=%x-%j.out\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=NetID@mcw.edu # NetID is your username\n\necho \"Starting at $(date)\"\necho \"Job name: ${SLURM_JOB_NAME}, Job ID: ${SLURM_JOB_ID}\"\necho \"I have ${SLURM_CPUS_ON_NODE} CPUs on compute node $(hostname -s)\"\n</code></pre>"},{"location":"user-guide/quickstart/#submit-the-job","title":"Submit the job","text":"<p>Now I can submit my example job:</p> <pre><code>sbatch test-job.slurm\n</code></pre> <p>Then I can check my job status:</p> <pre><code>squeue\n</code></pre>"},{"location":"user-guide/quickstart/#more-info","title":"More info","text":"<p>This guide has links to additional information about each topic. We strongly recommend to review all documentation.</p> <p>Need help getting started? Send us an email at help-rcc@mcw.edu.</p>"},{"location":"user-guide/access/login/","title":"Logging in","text":"<p>Remote Access</p> <p>Off-campus access to RCC resources is dependent on MCW-IS standard remote access methods. See Remote Access for more details.</p>"},{"location":"user-guide/access/login/#open-ondemand","title":"Open OnDemand","text":"<p>Open OnDemand is a web browser-based interface to RCC computing resources. You can manage files, submit and monitor jobs, and run pre-configured interactive apps such as Jupyter and RStudio. All of this is possible without logging in via a traditional SSH terminal.</p> <p>This is the recommended login method for most users. For more info, see Open OnDemand.</p>"},{"location":"user-guide/access/login/#ssh-connection","title":"SSH Connection","text":"<p>For advanced use case, SSH may be used to login. Please see SSH Connection for information about SSH clients and logging in.</p>"},{"location":"user-guide/access/ondemand/","title":"Open OnDemand","text":"<p>Open OnDemand is a web browser-based interface to RCC computing resources. You can manage files, submit and monitor jobs, and run pre-configured interactive apps such as Jupyter and RStudio. All of this is possible without logging in via a traditional SSH terminal.</p>"},{"location":"user-guide/access/ondemand/#documentation","title":"Documentation","text":"<p>This documentation is specific for RCC's Open OnDemand instance. Open OnDemand was created by the Ohio Supercomputer Center, which provides full documentation.</p>"},{"location":"user-guide/access/ondemand/#connecting-to-open-ondemand","title":"Connecting to Open OnDemand","text":"<p>Browser Support</p> <p>No IE 11 support. To have the best experience using Open OnDemand, use the latest versions of Google Chrome, Mozilla Firefox or Microsoft Edge.</p>"},{"location":"user-guide/access/ondemand/#on-campus","title":"On Campus","text":"<p>To connect to Open OnDemand point your browser to https://ondemand.rcc.mcw.edu. Open OnDemand is configured to use your MCW username and password. Access does require you have an RCC user account.</p> <p>After login, the Dashboard will appear. The menu includes apps to manage files, submit jobs, monitor jobs, open a terminal session, or launch interactive apps. To end your session, click Log Out at the top right.</p>"},{"location":"user-guide/access/ondemand/#off-campus","title":"Off Campus","text":"<p>Open OnDemand is available for remote work through Citrix. Please see the remote access guide for details.</p> <p>To access Open OnDemand, point your Citrix web browser to https://ondemand.rcc.mcw.edu.</p>"},{"location":"user-guide/access/ondemand/#shell-access","title":"Shell Access","text":"<p>Shell access is available to cluster login nodes. From the Dashboard menu, select Clusters &gt; Cluster Shell Access A new window will open and you will be logged in to a cluster login node. This shell access is the same as if you had used a Terminal app from your desktop (i.e. Putty, SSH Secure Shell, MobaXterm, etc.).</p> <p>The shell app now supports themes!</p> <p>You can customize the them of your OOD shell by selecting a new option from the themes drop-down menu in the upper right-hand corner of the window.</p> <p>Logout!</p> <p>When you are done with your shell, please logout with the <code>exit</code> or <code>quit</code> commands.</p>"},{"location":"user-guide/access/ondemand/#file-management","title":"File Management","text":"<p>The Files menu contains links to common storage locations. Clicking one of the file links opens the File Explorer in a new browser tab.</p> Button Function <code>Open in Terminal</code> Open current directory in a terminal window in a new browser tab <code>New File</code> Create a new, empty file <code>New Directory</code> Create a new directory <code>Upload</code> Upload a file from your local machine <code>Download</code> Download selected file to your local machine <code>Copy/Move</code> Copy selected file to clipboard <code>Delete</code> Delete selected file <code>Show Owner/Mode</code> Toggle the display of owner and permission settings <code>Show Dotfiles</code> Toggle the display of dotfiles (files starting by a ., which are usually hidden) <code>Filter</code> Filter files/folders by pattern <p>Each file and folder will have additional options. Select the <code>\u22ee</code> dropdown menu to rename, download, delete, view (file only), or edit (file only) a single item.</p>"},{"location":"user-guide/access/ondemand/#upload-a-file","title":"Upload a File","text":"<p>To upload a file, select the Upload button. Then use the file selector to choose a file to upload. Please note that this only works for individual files. If you need to upload a folder, see Upload a Folder.</p>"},{"location":"user-guide/access/ondemand/#upload-a-folder","title":"Upload a Folder","text":""},{"location":"user-guide/access/ondemand/#on-campus_1","title":"On-Campus","text":"<p>To upload a folder, drag and drop the folder from your local desktop to your OnDemand Files app browser window. As you drag the folder to the window, your cursor should show a copy indicator.</p>"},{"location":"user-guide/access/ondemand/#off-campus_1","title":"Off-Campus","text":"<p>If you're off-campus, you'll be accessing OnDemand via Citrix browser. To upload a folder, drag and drop the folder from your Windows File Explorer (Citrix app) to your OnDemand Files app (Citrix browser window). Again, as you drag the folder to the window, your cursor should show a copy indicator.</p>"},{"location":"user-guide/access/ondemand/#job-submission","title":"Job Submission","text":"<p>Jobs can be created, submitted, and monitored via the Jobs Menu. This is an alternative to creating and submitting job scripts in the command line.</p> <p>From the Dashboard menu, select Jobs &gt; Job Composer which will open in a new window. The Job Composer app has two tabs: Jobs and Templates The Jobs tab contains a list of all jobs previously submitted through Open OnDemand. The Templates tab allows you to create your own job templates.</p> <p>Jobs can be created from previous jobs or job templates. See OSC's Job Management Guide for more information.</p>"},{"location":"user-guide/access/ondemand/#create-a-new-job","title":"Create a New Job","text":"<p>In the Job Composer app, select the Jobs tab. To create a new job script, click the + New Job button and select From Default Template You'll see a new job script entry with status Not Submitted. On the right hand side you'll see the Job Details, including the location and name of the job script.</p>"},{"location":"user-guide/access/ondemand/#edit-a-job-script","title":"Edit a Job Script","text":"<p>The default job template creates a new generic job script. You'll need to edit this job script so that it contains the workflow you'll submit to the cluster. To edit a job script, click the Open Editor button at the lower right.</p> <p>This will open a job editor in a new tab. You should write your job script following the normal SLURM job syntax. For information on writing SLURM job scripts, see the Job Script Guide. After editing the job script, save the script and close the editor window.</p>"},{"location":"user-guide/access/ondemand/#edit-job-options","title":"Edit job options","text":"<p>Click the blue Job Options button. Here you can change the job name and the cluster where the job will run. Click Save or Back to close the job options window.</p>"},{"location":"user-guide/access/ondemand/#submit-a-job","title":"Submit a Job","text":"<p>To submit a job, select a job and click the green Submit button. A message at the top of the window will indicate if the job submission was successful or not. After job submission, the job status will change to Queued or Running When the job completes, the status will show Completed</p>"},{"location":"user-guide/access/ondemand/#monitor-jobs","title":"Monitor Jobs","text":"<p>From the Dashboard menu, select Jobs &gt; Active Jobs for a live view of the cluster queue. You can view all jobs, your own jobs, and select by cluster.</p>"},{"location":"user-guide/access/ondemand/#interactive-applications","title":"Interactive Applications","text":"<p>Open OnDemand features several interactive applications that run on cluster nodes and are accessed through the web interface. This allows you to run interactive apps directly in your web browser.</p> <p>GUI Apps</p> <p>Some Open OnDemand apps require a Graphical User Interface (GUI). One example is the Remote Desktop app. When starting a GUI app, you can select Compression and Image Quality settings before connecting. Most sessions will run best with minimum compression and maximum image quality. If you have a slow network connection, you can maximize compression and minimize image quality.</p>"},{"location":"user-guide/access/ondemand/#jupyter-notebook-example","title":"Jupyter Notebook Example","text":"<p>Here we focus on the Jupyter Notebook app as a popular example, but there are many apps to choose from. Check the full app list for details.</p> <p>To start a Jupyter Notebook on a cluster server:</p> <ol> <li>From the Dashboard menu, select Interactive Apps &gt; Jupyter Notebook. You'll see two categories in the Interactive Apps drop-down menu. Select for the resource you need.</li> <li>The My Interactive Sessions screen will open. Select for the resource parameters that you need. You can also select to be notified by email when your session will start. </li> <li>Click the Launch button to start your Jupyter Notebook session. You may have to wait for cluster resources to become available.</li> <li>Once the session starts, click the Connect to Jupyter button. A Jupyter Notebook will open in a new window. </li> <li>To terminate your Jupyter Notebook session, go back to the My Interactive Sessions page and click the red Delete button.</li> </ol> <p>Did you know you can also use your own Python environment in your Jupyter Notebook session?</p> <p>If you have installed a Python environment in your home directory, then you can generate a Jupyter kernel which can then be used in your Jupyter Notebook session.</p> <pre><code># login to the cluster and run the following, replacing myenv with the name of your Python env\n$ source activate myenv\n$ python -m ipykernel install --user --name myenv --display-name \"Python (myenv)\"\n</code></pre>"},{"location":"user-guide/access/remote-access/","title":"Remote Access","text":"<p>Off-campus access to RCC resources is dependent on MCW-IS standard remote access methods. For more information on remote work, see Remote Work Guide. RCC resources are available remotely using Citrix.</p>"},{"location":"user-guide/access/remote-access/#citrix","title":"Citrix","text":"<p>Citrix is the recommended method of remote access to RCC resources. Citrix is available off-campus using MFA for login.</p>"},{"location":"user-guide/access/remote-access/#putty-in-citrix","title":"PuTTY in Citrix","text":"<p>PuTTY is a well-documented terminal application used for SSH access to Linux systems. Contact the MCW-IS help desk to request PuTTY for your Citrix account.</p> <p>To access PuTTY, first login to Citrix. From the Citrix home page, select Admin Tools, then select PuTTY.</p>"},{"location":"user-guide/access/remote-access/#open-ondemand-in-citrix","title":"Open OnDemand in Citrix","text":"<p>Use the web browser in Citrix to access RCC's Open OnDemand service. This is a web-portal for utilizing our HPC resources. This access includes file browsing, SSH access, job management, etc. For more information, please see Open OnDemand.</p> <p>To access Open OnDemand, first login to Citrix. From the Citrix home page, select Browsers, and select your Citrix web browser of choice. Open OnDemand is most stable in Google Chrome.</p> <p>Point your Citrix web browser to https://ondemand.rcc.mcw.edu.</p>"},{"location":"user-guide/access/ssh/","title":"SSH Connection","text":"<p>Traditional SSH connection is available for all clusters. However, we do recommend to use Open OnDemand if possible.</p>"},{"location":"user-guide/access/ssh/#ssh-clients","title":"SSH clients","text":"<ul> <li>PuTTY - simplest SSH client for Windows and requires no install</li> <li>Mac Terminal App - built-in terminal app available on all Mac computers</li> <li>Iterm2 - enhanced terminal app for Mac computers</li> <li>Linux terminal - built-in terminal apps are available in most Linux OS</li> </ul>"},{"location":"user-guide/access/ssh/#using-ssh-to-login","title":"Using SSH to login","text":"<p>Each SSH client will vary in specific detail but all will ask for a hostname, username, and password.</p>"},{"location":"user-guide/access/ssh/#hostname","title":"Hostname","text":"<p>Each login hostname follows a common naming convention, login-clustername.rcc.mcw.edu.</p> <p>Depending on your permissions, you may login to the following clusters:</p> <ul> <li>login-hpc.rcc.mcw.edu - primary SLURM cluster</li> </ul>"},{"location":"user-guide/access/ssh/#username","title":"Username","text":"<p>When asked for your username, please use your MCW NetID, which is used for most MCW resources including email login.</p>"},{"location":"user-guide/access/ssh/#password","title":"Password","text":"<p>When prompted, enter your MCW password, which is used for most MCW resources including email login.</p> <p>Never share your password</p> <p>MCW policy prohibits sharing of passwords. Research Computing staff never has access to your password, and will never ask you for your password.</p>"},{"location":"user-guide/access/ssh/#example-login","title":"Example login","text":"<p>In a command-line session:</p> <pre><code>ssh netid@login-clustername.rcc.mcw.edu\n</code></pre> <p>Hidden Password</p> <p>Most SSH client applications will hide your password as you type. This is a security feature, not an error.</p>"},{"location":"user-guide/access/ssh/#ssh-options","title":"SSH options","text":"<p>OpenSSH has many configuration options that you can use to customize your login experience. Custom SSH options are added to <code>~/.ssh/config</code> on your local computer.</p>"},{"location":"user-guide/access/ssh/#custom-hostnames","title":"Custom hostnames","text":"<p>You can customize and simplify the login hostnames with a host entry in <code>~/.ssh/config</code>.</p> <pre><code>Host login-hpc\n    HostName login-hpc.rcc.mcw.edu\n    User netid\n</code></pre> <p>This will simplify:</p> <p><code>ssh netid@login-hpc.rcc.mcw.edu</code></p> <p>to:</p> <p><code>ssh login-hpc</code></p>"},{"location":"user-guide/jobs/running-jobs/","title":"Running Jobs","text":"<p>We use SLURM (Simple Linux Utility for Resource Management) for submitting, scheduling, and monitoring workloads, which we call jobs. Each job consists of resource requests and a set of commands to run. SLURM helps to schedule these jobs to run on the cluster using efficient methods to maximize throughput and minimize waiting. From the moment you submit a job, SLURM will make many decisions about priority of your workload, fair utilization of the cluster, and which resource is best to complete your job.</p> <p>Clusters are shared resources.</p> <p>Please be respectful of all other users. Do not start resource-intensive scripts on a login node. Do not request more resources than your job can use. For more info see User Etiquette.</p> <p>Need help scheduling your job? Send us an email at help-rcc@mcw.edu.</p>"},{"location":"user-guide/jobs/running-jobs/#about-slurm","title":"About SLURM","text":"<p>As a cluster workload manager, SLURM has three key functions. First, it allocates exclusive and/or non-exclusive access to resources (compute nodes) to users for some duration of time so they can perform work. Second, it provides a framework for starting, executing, and monitoring work (normally a parallel job) on the set of allocated nodes. Finally, it arbitrates contention for resources by managing a queue of pending work.</p>"},{"location":"user-guide/jobs/running-jobs/#common-slurm-commands","title":"Common SLURM Commands","text":"<p>These are the most common SLURM commands.</p> <p>Submit a batch job script:</p> <pre><code>sbatch test-job.slurm\n</code></pre> <p>List queued and running jobs:</p> <pre><code>squeue\n</code></pre> <p>Show information about a running job:</p> <pre><code>squeue -j jobId # jobId is the job number\n</code></pre> <p>Cancel a queued job or stop a running job:</p> <pre><code>scancel jobId # jobId is the job number\n</code></pre> <p>Show history of job:</p> <pre><code>sacct -j jobId # jobId is the job number\n</code></pre> <p>RCC provides an additional command <code>slurminfo</code>.</p> <p>Use this command to see cluster info and a summary of SLURM stats.</p> <p> <pre><code>$ slurminfo\n       QUEUE   FREE  TOTAL   FREE  TOTAL   RESORC    OTHER  MAXJOBTIME    CORES    NODE  GPU      PARTITION  CORES  CORES  NODES  NODES  PENDING  PENDING   DAY-HR:MN    /NODE  MEM-GB (COUNT)\nnormal   2066   2880     41     60        0      144     7-00:00       48     360 -         bigmem     48     96      0      2        0        0     7-00:00       48    1500 -         gpu    223    384      1      8        0       12     7-00:00       48 360-480 gpu:v100:4(S:0-1)(6),gpu:a40:4(S:0-3)(2)\n</code></pre> </p>"},{"location":"user-guide/jobs/running-jobs/#managing-job-inputoutput-files","title":"Managing Job Input/Output Files","text":"<p>The new HPC system requires a specific job workflow:</p> <ol> <li>Copy job input/supporting files from your RGS directory within <code>/group/PI_NetID/...</code> to your scratch directory <code>/scratch/u/NetID</code> or <code>/scratch/g/PI_NetID</code></li> <li>Submit a job from your <code>/scratch/...</code> directory that utilizes the staged job input/supporting files. You must make sure the job I/O runs in your scratch directory. The easiest way is to run the sbatch command in your <code>/scratch/...</code> directory.</li> <li>When job finishes, copy results from <code>/scratch/...</code> back to <code>/group/PI_NetID/</code>....</li> <li>If there are further computations, continues utilizing the job input/supporting files</li> <li>When jobs are finished and staged job input/supporting files are no longer needed, delete the job input/supporting files from <code>/scratch/...</code></li> </ol> <p>Warning</p> <p>Your jobs will fail if you do not follow this procedure. Please note that files in <code>/scratch/...</code> that are older than 180 days will be deleted.</p>"},{"location":"user-guide/jobs/running-jobs/#slurm-concepts","title":"SLURM Concepts","text":""},{"location":"user-guide/jobs/running-jobs/#nodes-cores-tasks","title":"Nodes, Cores &amp; Tasks","text":"<p>Before we discuss writing jobs scripts, or submitting jobs, it is important to understand how resources are requested and allocated through SLURM on HPC. SLURM uses three <code>#SBATCH</code> directives, <code>--ntasks</code>, <code>--nodes</code>, and <code>--cpus-per-task</code>, which can be used to run . SLURM uses the concept of tasks, which are processes that can use one or more CPU cores to run a copy of a program. Below we'll discuss how nodes, cores, and tasks are used by single-thread, multi-thread, multi-process, and MPI applications.</p>"},{"location":"user-guide/jobs/running-jobs/#single-thread","title":"Single-thread","text":"<p>Many applications are only able to use one CPU core. For these single-thread programs, one task running on one core will suffice.</p> <pre><code>#SBATCH --ntasks=1\n</code></pre> <p>Most applications do not use more than one CPU core. Single-thread jobs that request multiple cores, waste resources. If your application does not mention multi-thread, multi-core, or MPI, please do not request more than one CPU core. When in doubt, contact RCC for clarification.</p>"},{"location":"user-guide/jobs/running-jobs/#multi-thread","title":"Multi-thread","text":"<p>A multi-thread application is able to use multiple cores on a single system by spawning multiple threads from a single process. Each thread uses one CPU core, and all share memory. For a multi-thread application, we can use a single task, and specify multiple cpus per task.</p> <pre><code>#SBATCH --ntasks=1\n#SBATCH --cpus-per-task=4\n</code></pre> <p>In this case, the job requests one task that can use 4 CPU cores. The user's application should then start one process that runs 4 threads.</p> <p>Since all CPU cores are attached to one process, multi-thread applications cannot use more than one system. Multi-thread jobs that request multiple nodes, waste resources. If your application does not say MPI, please do not request more than one node. If your application does not mention multi-thread, multi-core, or MPI, please do not request more than one CPU core. When in doubt, contact RCC for clarification.</p>"},{"location":"user-guide/jobs/running-jobs/#multi-process","title":"Multi-process","text":"<p>A multi-process application, often referred to as \"embarrassingly parallel\", is able to use multiple cores by starting multiple independent processes. Each process uses one CPU core. For a multi-process application, we request multiple tasks.</p> <pre><code>#SBATCH --ntasks=4\n</code></pre> <p>In this case, the job requests 4 tasks, which will use 4 CPU cores. Each task can run one copy of the user's application on one CPU core. If your application does not mention multi-thread, multi-core, or MPI, please do not request more than one CPU core. When in doubt, contact RCC for clarification.</p>"},{"location":"user-guide/jobs/running-jobs/#mpi","title":"MPI","text":"<p>A multi-process application that is written to use Message Passing Interface (MPI), is able to use multiple cores across multiple nodes. MPI uses the SLURM task information to distribute the application processing across multiple cores and nodes. Each MPI process is able to communicate with the others using the high-performance, low-latency network. Therefore, an MPI application can scale across cores and nodes with little drop in performance. For a MPI application, we request multiple nodes and multiple tasks.</p> <pre><code>#SBATCH --nodes=4\n#SBATCH --ntasks-per-node=8\n</code></pre> <p>In this case, the job requests 4 nodes, each running 8 MPI processes. The total number of MPI processes is equal to <code>nodes * tasks-per-node</code>. SLURM will run these MPI processes with the fewest nodes possible. In our case above, we request 4 nodes and 8 tasks-per-node, or 32 total MPI processes. If we run this job on HPC, SLURM will use 1 node and 32 CPU cores, since HPC has 48 cores per node. If we had requested a higher number of tasks-per-node, SLURM would allocate multiple nodes. This is all done transparently by SLURM.</p> <p>Please note that there are far fewer MPI applications than single- or multi-thread. If your application does not specifically mention MPI in its documentation, it probably does not support MPI. Again, single- or multi-thread jobs that request multiple nodes, waste resources. If your application does not say MPI, please do not request more than one node. When in doubt, contact RCC for clarification.</p>"},{"location":"user-guide/jobs/running-jobs/#partitions","title":"Partitions","text":"<p>SLURM partitions are equivalent to Torque queues. Partitions organize nodes in groups by type, and allow for scheduling, priority, fairshare, and more. The new HPC system uses 3 partitions, normal, bigmem, and gpu. The partition configuration is a work in progress as we adjust resource limits.</p> <p>Default Partition</p> <p>The <code>--partition</code> flag is not required for jobs.</p>"},{"location":"user-guide/jobs/running-jobs/#normal","title":"Normal","text":"<p>The normal partition contains the CPU-only nodes, cn01-cn60. This is the default partition, so any job that does not specify a partition will run in normal. Each node in this partition has 48 cores, 360GB RAM, and a 480GB SSD for local scratch. Most jobs should use this partition, especially if you're using an MPI application. A job that does not parallelize, should use 1 core. A job that does not use MPI, should use 48 cores or less. Jobs using MPI can use multiple nodes.</p>"},{"location":"user-guide/jobs/running-jobs/#bigmem","title":"Bigmem","text":"<p>The bigmem partition contains the large memory nodes, hm01-hm02. Each node in this partition has 48 cores, 1.5TB RAM, and a 480GB SSD for local scratch. Use the <code>#SBATCH --partition=bigmem</code> directive to have your job run on a large memory server.</p>"},{"location":"user-guide/jobs/running-jobs/#gpu","title":"GPU","text":"<p>The gpu partition contains the gpu nodes. Nodes gn01-gn06 each have 48 cores, 360GB RAM, 4 V100 GPUs, and a 480GB SSD for local scratch. Nodes gn07-gn08 each have 48 cores, 480GB RAM, 4 A40 GPUs, and a 3.84TB NVMe SSD for local scratch. Use the <code>#SBATCH --partition=gpu</code> and <code>#SBATCH --gres=gpu:1</code> directives to have your job run on a gpu node.</p> <p>GPU Type</p> <p>To use a specific GPU type, use <code>#SBATCH --gres=gpu:type:1</code>, where type is either <code>v100</code> or <code>a40</code>. Please note that most jobs will not benefit from specifying a GPU type, and this may delay scheduling of your job.</p>"},{"location":"user-guide/jobs/running-jobs/#qos","title":"QOS","text":"<p>A Quality Of Service (QOS) modifier combines additional job resource limits and settings to existing partitions. The dev QOS is meant to allow interactive, development, and/or debugging jobs to be more responsive on the new cluster. This QOS has more restricted limits for these jobs, since dev/debug jobs are not considered production jobs. However, the benefit of dev QOS is the higher priority setting, which in many cases will float your job to the top of the queue, potentially allowing it to run quicker. The dev QOS can be combined with any partition, so that these jobs can be combined with specialized resources such as high memory or GPU.</p>"},{"location":"user-guide/jobs/running-jobs/#job-scheduling-policies","title":"Job Scheduling Policies","text":"<p>Job scheduling policies include resource limits on partitions and QOS's, and a fairshare algorithm. The fairshare configuration is currently in development.</p>"},{"location":"user-guide/jobs/running-jobs/#resource-limits","title":"Resource Limits","text":"Partition Max Time (default) Max Nodes/User Max Cores/User Max GPUs/User Max Mem/Core (default) Priority normal 7 days (2 hrs) 30 1440 N/A 7.5GB (7.5GB) 10 bigmem 7 days (2 hrs) 1 48 N/A 31GB (31GB) 10 gpu 7 days (2 hrs) 4 192 16 10GB (7.5GB) 10 QOS Max Time Max Nodes/User Max Cores/User Max GPUs/User Max Mem/Core (default) Priority dev 8 hrs 1 8 1 7.5GB (7.5GB) 10000"},{"location":"user-guide/jobs/running-jobs/#fairshare","title":"Fairshare","text":"<p>Fairshare is a scheduler algorithm that manages job priority, based on a comparison of all cluster utilization, to promote equal use the cluster. Fairshare tracks daily usage and uses data from the previous 7 days to adjust job priority. The effect of fairshare data is reduced each day using a decay factor. In practice, when a user increases their cluster utilization, their job priority is lowered compared to other users.</p> <p>Fairshare effectively allows infrequent users a fair chance to run their jobs on the cluster among the many jobs of more frequent users.</p>"},{"location":"user-guide/jobs/running-jobs/#writing-a-job-script","title":"Writing a Job Script","text":"<p>Job scripts are required to run jobs in the queueing system. A job script is a text file using shell script syntax, denoted by the required first line, <code>#!/bin/bash</code>. It can be broken into two sections; resource requests and executable commands. Each section will be explained using the following example SLURM job script that can be used as a starting template for your jobs.</p> test-job.slurm <pre><code>#!/bin/bash\n#SBATCH --job-name=test-job\n#SBATCH --ntasks=1\n#SBATCH --mem-per-cpu=1gb\n#SBATCH --time=00:01:00\n#SBATCH --account=PI_NetID\n#SBATCH --partition=partition\n#SBATCH --output=%x-%j.out\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=NetID@mcw.edu\n\necho \"Starting at $(date)\"\necho \"Job name: ${SLURM_JOB_NAME}, Job ID: ${SLURM_JOB_ID}\"\necho \"I have ${SLURM_CPUS_ON_NODE} CPUs on compute node $(hostname -s)\"\n</code></pre>"},{"location":"user-guide/jobs/running-jobs/#job-requests","title":"Job Requests","text":"<p>This section is comprised of <code>#SBATCH</code> directives that tell the scheduler what resources you're requesting. Some of the directives are required, as noted below. The job request section is always required at the top of a job script, but there is no specific order for the <code>#SBATCH</code> directives. While more than one directive can be combined on a single line, RCC does recommend a separate line for each.</p>"},{"location":"user-guide/jobs/running-jobs/#job-name","title":"Job Name","text":"<p>A job name is required and is set with the <code>#SBATCH --job-name=</code> option. Your job will appear in the queue with this name and job output files may be based on it. Letters, digits, underscore, and hyphens are allowed.</p> <pre><code>#SBATCH --job-name=myCoolJobName ### REQUIRED\n</code></pre>"},{"location":"user-guide/jobs/running-jobs/#cpu-resources","title":"CPU Resources","text":"<p>A CPU resource request is required and tells the queueing system how to allocate processes. CPU resources can include <code>--ntasks</code>, <code>--cpus-per-task</code>, <code>--nodes</code>, or <code>--ntasks-per-node</code>.</p> <pre><code>#SBATCH --ntasks=1\n</code></pre> <p>Please see Nodes, Cores &amp; Tasks for more information.</p>"},{"location":"user-guide/jobs/running-jobs/#memory","title":"Memory","text":"<p>A memory request is required and tells the queueing system how much memory to allocate to processes. SLURM has default- and maximum-memory-per-core settings. If your job is single-thread, please use the <code>--mem</code> flag. If your job is multi-thread or MPI, please use the <code>--mem-per-cpu</code> flag. Please note that SLURM enforces memory per core and total memory. Your job will fail if your application exceeds the memory you requested, or the total available memory.</p> <pre><code>#SBATCH --mem=1gb\n</code></pre>"},{"location":"user-guide/jobs/running-jobs/#time","title":"Time","text":"<p>A time request is required and tells SLURM how long your job will run. This is equivalent to Torque walltime. The <code>--time</code> flag sets the max time, in DD-HH:MM:SS, that your job can run. If your job exceeds that time limit, it will fail. SLURM is also configured with default and max time limits.</p> <pre><code>#SBATCH --time=00:01:00\n</code></pre> <p>Does your job require more than the maximum 7 day time limit?</p> <p>Email the jobid number and time extension request to help-rcc@mcw.edu</p>"},{"location":"user-guide/jobs/running-jobs/#account","title":"Account","text":"<p>An account is required for your job to run. The <code>--account</code> option should be set to your PI's NetID, or the NetID of a collaborator PI. If you need to adjust your account membership, please contact RCC.</p> <pre><code>#SBATCH --account=PI_NetID\n</code></pre> <p>You can easily find your accounts with the <code>myaccts</code> command.</p> <p> <pre><code>$ myaccts\nAccount        Partition\npi             bigmem,dev,gpu,normal\n</code></pre> </p>"},{"location":"user-guide/jobs/running-jobs/#partition","title":"Partition","text":"<p>A partition is not required but can be added with <code>#SBATCH --partition=</code>. The partition flag is only needed if requesting complex resources, such as the large memory or GPU nodes.</p> <pre><code>#SBATCH --partition=&lt;partition&gt;\n</code></pre>"},{"location":"user-guide/jobs/running-jobs/#job-output","title":"Job Output","text":"<p>A job output flag is not required. By default SLURM will send job output to <code>slurm-%j.out</code> in the working directory, where <code>%j</code> is the SLURM jobid. If the <code>--output</code> flag is used, SLURM will output the application's STDOUT to the given filename. In our example script, SLURM output is sent to <code>%x-%j.out</code>, where <code>%x</code> is the job name.</p> <pre><code>#SBATCH --output=%x-%j.out\n</code></pre>"},{"location":"user-guide/jobs/running-jobs/#notifications","title":"Notifications","text":"<p>Notifications are optional and can be sent from the queueing system to an email address of your choice. Many types are supported, but common options include when a job begins <code>#SBATCH --mail-type=BEGIN</code>, when a job ends <code>#SBATCH --mail-type=END</code>, and when a job fails <code>#SBATCH --mail-type=FAIL</code>. Options may be combined, i.e. <code>#SBATCH --mail-type=BEGIN,END</code>. There is also an option to send all notifications <code>#SBATCH --mail-type=ALL</code> The recipient email is specified with <code>#SBATCH --mail-user=NetID@mcw.edu</code>. RCC recommends using notifications during job debugging. Adding notifications as a default may result in email spam, especially if you're submitting many jobs.</p> <pre><code>#SBATCH --mail-type=ALL ### OPTIONAL\n#SBATCH --mail-user=NetID@mcw.edu ### OPTIONAL\n</code></pre>"},{"location":"user-guide/jobs/running-jobs/#job-commands","title":"Job Commands","text":"<p>The job commands section always follows the job request section and begins with the first non #SBATCH line. Executable commands commonly include file I/O, software commands, and directory cleanup.</p> <pre><code>echo \"Starting at $(date)\"\necho \"Job name: ${SLURM_JOB_NAME}, Job ID: ${SLURM_JOB_ID}\"\necho \"I have ${SLURM_CPUS_ON_NODE} CPUs on compute node $(hostname -s)\"\n</code></pre> <p>In the example job script, the job commands include several environment variables that are created by SLURM when your job starts. These can be useful to automate tasks or print helpful information about your job to your output file.</p>"},{"location":"user-guide/jobs/running-jobs/#submit-a-batch-job","title":"Submit a Batch Job","text":"<p>Most jobs that run on HPC are batch jobs. A batch job is submitted with the <code>sbatch</code> command and requires a job script. This is the best method for production job as it allows you to submit many jobs and let SLURM do the work. With a batch job, there is no requirement that you sit and watch the command-line. You can submit the job and come back later.</p> <pre><code>sbatch test-job.slurm\n</code></pre> <p>A job script is required. If you haven't already, please review Writing a Job Script.</p>"},{"location":"user-guide/jobs/running-jobs/#submit-an-interactive-job","title":"Submit an Interactive Job","text":"<p>Users may need an interactive session for debugging or related tasks. An interactive job is submitted with the <code>srun</code> command. All of the SLURM options that are required in job scripts are required with the <code>srun</code> command. In addition, <code>--qos=dev</code> is added automatically.</p> <pre><code>srun --ntasks=1 --mem-per-cpu=4GB --time=01:00:00 --job-name=interactive --account=PI_NetID --pty bash\n</code></pre> <p>To stop your interactive job, use the <code>exit</code> command.</p> <pre><code>exit\n</code></pre> <p>Open OnDemand</p> <p>We encourage all users to make use of Open OnDemand for interactive sessions.</p>"},{"location":"user-guide/jobs/running-jobs/#gpu-jobs","title":"GPU Jobs","text":"<p>The new HPC system includes 6 compute nodes that each have 4 V100 accelerators. There is no need to login to a separate cluster as in the past. You can add a GPU to your batch or interactive job submission with the <code>--gres=gpu:&lt;N&gt;</code> command, where N is the number of GPUs.</p> <p>In a job script add:</p> <pre><code>#SBATCH --gres=gpu:1\n#SBATCH --partition=gpu\n</code></pre> <p>Interactive job command:</p> <pre><code>srun --ntasks=1 --mem-per-cpu=4GB --gres=gpu:1 --time=01:00:00 --job-name=interactive --partition=gpu --account=PI_NetID --pty bash\n</code></pre>"},{"location":"user-guide/jobs/running-jobs/#debugdev-jobs","title":"Debug/Dev Jobs","text":"<p>The new HPC system includes a special <code>dev</code> QOS. Any job using this QOS will have a higher priority than non-QOS jobs. The goal is for a interactive/dev/debug job to start running quicker, to speed up the developer's work. While this QOS will attempt to move your job to the top of the queue, it does not guarantee the job will start immediately. This can be combined with any of the other partition and gres requests.</p> <p>In a job script add:</p> <pre><code>#SBATCH --qos=dev\n#SBATCH --partition=&lt;partition&gt;\n</code></pre>"},{"location":"user-guide/jobs/running-jobs/#array-jobs","title":"Array Jobs","text":"<p>A job array is used to submit multiple similar jobs. Each element in the array represents an independent subjob.</p> <p>Job arrays are submitted with the SLURM option <code>--array=x-y</code>. Here we specify an array with index 1-5, or 5 subjobs.</p> <pre><code>#SBATCH --array=1-5\n</code></pre> <p>If the SLURM job number is 1000, then the array subjobs will have ids <code>1000_1</code>, <code>1000_2</code>, ..., <code>1000_5</code>. Each subjob will also have an environment variable <code>SLURM_ARRAY_TASK_ID</code> that is set to its array index value.</p> <p>When submitting many jobs at once, the job array can limit the number of subjobs running at a time. Here we specify an array with index 1-50, limited to 5 running at a time.</p> <pre><code>#SBATCH --array=1-50%5\n</code></pre> <p>A job array can be deleted with the <code>scancel</code> command.</p> <pre><code>scancel 1000\n</code></pre> <p>Alternatively, a single subjob can be deleted.</p> <pre><code>scancel 1000_3\n</code></pre> <p>Example: We want to run the same code on 50 different input files. The input files are conveniently named <code>input-1</code>, <code>input-2</code>, etc. The following script will process all 50 input files, 5 at a time.</p> test-array-job.slurm <pre><code>#!/bin/bash\n#SBATCH --job-name=array_example\n#SBATCH --nodes=1\n#SBATCH --ntasks=5\n#SBATCH --mem-per-cpu=1gb\n#SBATCH --time=00:10:00\n#SBATCH --array=1-50%5\n#SBATCH --output=array_%A-%a.out\n\ncommand input-${SLURM_ARRAY_TASK_ID}\n</code></pre>"},{"location":"user-guide/jobs/software-job/","title":"Loading Software in a Job","text":"<p>For most jobs, you'll need to load software prior to running your commands. Module commands are used to add a software environment, including executable commands and environment variables. For convenience, you can use an abbreviation <code>ml</code>, in place of the <code>module</code> command.</p> <pre><code>#!/bin/bash\n#SBATCH ...\n#SBATCH ...\n#SBATCH ...\n\nml reset\nml load R/4.1.1\n\nRscript ...\n</code></pre> <p>Please see the software modules guide for more detail.</p>"},{"location":"user-guide/jobs/storage-job/","title":"Staging Data","text":"<p>RCC storage includes a persistent <code>/group</code> space and a transient <code>/scratch</code> space. The <code>/group</code> storage is not available on compute nodes, for performance reasons. Therefore, it is necessary to stage your data into and out of <code>/scratch</code>. If your job has a large input dataset, we suggest to copy the data before the job. If input data is relatively small, you can add the staging step to the job.</p> <p>Data staging required</p> <p>Your job will fail and/or you will lose your job output if you do not properly stage your data to and from scratch. Contact help-rcc@mcw.edu for help with data staging.</p>"},{"location":"user-guide/jobs/storage-job/#workflow","title":"Workflow","text":"<ol> <li>User copies job input/supporting files from an RGS directory within <code>/group/{PI_NetID}/...</code> to their scratch directory <code>/scratch/g/{PI_NetID}</code></li> <li>User submits job that computes with the staged job input/supporting files</li> <li>Job finishes and user copies results from <code>/scratch/g/{PI_NetID}</code> back to <code>/group/{PI_NetID}/...</code></li> <li>User continues with further computations with the job input/supporting files</li> <li>User finishes computations and deletes unneeded job input/supporting files from <code>/scratch/u/{NetID}</code> or <code>/scratch/g/{PI_NetID}</code></li> </ol>"},{"location":"user-guide/jobs/troubleshoot/","title":"Troubleshoot Jobs","text":"<p>It is often the case that your job will fail, or not do what you intended. This guide will show you how to proactively monitor your job and diagnose issues both in real-time and retrospectively. Depending on the platform you use to access the cluster, there are a variety of options to monitor and diagnose job issues. We suggest that you familiarize yourself with all of these resources.</p>"},{"location":"user-guide/jobs/troubleshoot/#command-line","title":"Command-line","text":"<p>The command-line has many powerful tools to monitor your jobs and diagnose issues. The first tool is the <code>squeue</code> command, which prints the current set of jobs in the queue. Monitoring the queue is best practice after you submit any job. It will quickly tell you if your job is running, where it is running, and for how long. When the cluster is busy, or you violate a scheduler policy, your job may be stuck in the queue. This will tell you the status of your job(s), and give reasons for any related issues.</p> <p>To list only your jobs:</p> <pre><code>squeue -u NetID\n</code></pre> <p>Another useful command is <code>seff</code>, which prints the workload efficiency metrics for a job. Although you can run this tool during a job, it is best used after your job is finished. The output will give an estimate of CPU and memory efficiency, and is very useful when benchmarking a workload for memory limit.</p> <p>To list only your jobs:</p> <pre><code>$ seff 250\nJob ID: 250\nCluster: cluster\nUser/Group: user/sg-group\nState: COMPLETED (exit code 0)\nNodes: 1\nCores per node: 5\nCPU Utilized: 00:00:01\nCPU Efficiency: 6.67% of 00:00:15 core-walltime\nJob Wall-clock time: 00:00:03\nMemory Utilized: 0.00 MB (estimated maximum)\nMemory Efficiency: 0.00% of 30.00 GB (30.00 GB/node)\n</code></pre>"},{"location":"user-guide/jobs/troubleshoot/#accessing-compute-node","title":"Accessing Compute Node","text":"<p>You may want to access the compute that is running your job to see further information in real-time. Direct compute node access via SSH is prohibited. If you need to access a compute node command-line during your job, you should run the job interactively. Please see interactive jobs for details.</p> <p>While direct SSH to a compute node is prohibited, there are other ways to pull real-time diagnostics from the compute node(s) that are running your job. For instance, you can run an additional command within an already running job with the <code>srun</code> command.</p> <p>Suppose that we already have a running job on the cluster.</p> <pre><code>$ squeue -u NetID\n             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n263052    normal  testing    NetID  R       0:11      1 cn60\n</code></pre> <p>We can retrieve information, in this case hostname, from the compute node via <code>srun</code>.</p> <pre><code>$ srun --jobid 263052 hostname\ncn60.cluster.local\n</code></pre> <p>For useful diagnostics about running processes, we run the <code>ps u -u $USER</code> command.</p> <pre><code>$ srun --jobid 263052 ps u -u $USER\nUSER           PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\nusername     67486  0.0  0.0 126484  2836 pts/0    Ss+  12:31   0:00 /usr/bin/bash\nusername     73572  0.0  0.0 165776  1932 ?        R    12:37   0:00 /usr/bin/ps u -u username\n</code></pre> <p>Passing inline commands to <code>srun</code> is limited. However, you can pass a script to print more information.</p>"},{"location":"user-guide/jobs/troubleshoot/#web-portal-xdmod","title":"Web portal (XDMoD)","text":"<p>XDMoD collects job accounting data and node level metrics during all cluster jobs. This data can be used for troubleshooting in the event of a crashed job.</p> <p>Please see the XDMoD guide for more info.</p>"},{"location":"user-guide/jobs/xdmod/","title":"XDMoD","text":""},{"location":"user-guide/jobs/xdmod/#overview","title":"Overview","text":"<p>XDMoD (XSEDE Metrics on Demand) is a NSF-funded open source tool that provides a wide range of metrics including utilization and performance of HPC resources. This tool can be used to monitor and troubleshoot your HPC jobs. It can also be used to track and document your RCC utilization. Please note that XDMoD uses your MCW login credentials. If you have not run jobs on RCC's HPC systems, you will not see any data after login. Please contact help-rcc@mcw.edu with questions.</p> <p>Metrics are not real-time</p> <p>XDMoD processes data overnight, rather than in real-time. This allows the application to be very responsive when displaying data. However, this means that job data will not display in XDMoD until the following day. Processing occurs every day at midnight.</p>"},{"location":"user-guide/jobs/xdmod/#login","title":"Login","text":"<p>Access RCC's XDMoD site at https://xdmod.rcc.mcw.edu. Click Sign in in the upper left corner.</p> <p></p> <p>A login window will appear. Click the MCW logo.</p> <p></p> <p>You will be redirected to a login page. Enter your MCW credentials.</p> <p></p>"},{"location":"user-guide/jobs/xdmod/#user-guide","title":"User Guide","text":"<p>Please see the XDMoD User Guide for details on site features and navigation.</p>"},{"location":"user-guide/jobs/xdmod/#example-use-troubleshooting-a-job","title":"Example Use - Troubleshooting a Job","text":"<p>XDMoD collects job accounting data and node level metrics during all cluster jobs. This data can be used for troubleshooting in the event of a crashed job.</p> <p>To view job information in XDMoD:</p> <ol> <li>Select the Job Viewer tab and follow the on screen instructions for job lookup. Once you have selected and saved the job(s) of interest, new folders with the resource and job id appear in the Search History on the left.</li> <li>Select a job id to display job data. The Accounting data includes all information that XDMoD has gathered from the queuing system including job name, username, wait time, wall time, etc.</li> <li>The Executable information will show the job's node name and application if available.</li> <li>If your job shared the node with another job, the Peers tab will show the concurrent jobs (useful when memory issues occur).</li> <li>Summary metrics include the processor, disk, and network usage. Detailed metrics contain all available node level metrics from your job.</li> </ol>"}]}